library(corrplot)
library(ggplot2)
library(SuperLearner)
library(dplyr)                      # For the "filter" function
library(splitTools)                 # For the "partition" function
library(caret)
library(performanceEstimation)
library(ggm)
library(MLmetrics)
#monk 1
monk_train_1_hot = read.csv("./MONK/monk_1_train_hot.csv", header = FALSE)
#monk 1
monk_train_1_hot = read.csv("./MONK/monk_1_train_hot.csv", header = FALSE)
#monk 1
monk_train_1_hot = read.csv("./MONK/monk_1_train_hot.csv", header = FALSE)
#monk 1
monk_train_1_hot = read.csv("./MONK/monk_1_train_hot.csv", header = FALSE)
#controllo se esistono valori NA
colSums(is.na(monk_train_1_hot))
# creo input - output train
set.seed(1)
split_id <- partition(monk_train_1_hot$V1, p = c(train = 0.7, valid = 0.3))
train_output_1 = monk_train_1_hot[split_id$train,1]
train_input_1 = monk_train_1_hot[split_id$train,-1]
validation_input_1 = monk_train_1_hot[split_id$valid,-1]
validation_output_1 = monk_train_1_hot[split_id$valid,1]
# creo input - output test
monk_test_1_hot = read.csv("./MONK/monk_1_test_hot.csv", header = FALSE)
colSums(is.na((monk_test_1_hot)))
test_output_1 = monk_test_1_hot$V1
test_input_1 = subset(monk_test_1_hot,select = -V1)
#provo SuperLearner, se aggiungo SL.knn da errore durante le previsioni
#setto seme per riprodurre la CV ogni volta
#provare a vedere se si può cambiare iperparametri, es KSVM (vedi slide 9 SVM-other-info)
set.seed(3)
tune_ranger = list(num.trees = c(500,1000,2000),
mtry = c(floor(sqrt(ncol(train_input_1))),ncol(train_input_1)))
learner_ranger = create.Learner("SL.ranger", tune = tune_ranger, detailed_names = TRUE, name_prefix = "ranger")
tune_svm_rbf = list(kernel = "rbfdot", sigma = c(0.06, 0.01, 0.1), C = c(0.8, 1, 1.2))
learner_svm_rbf = create.Learner("SL.ksvm", tune = tune_svm_rbf, detailed_names = TRUE, name_prefix = "ksvm")
sl1 <- SuperLearner(Y = train_output_1, X = train_input_1, newX = validation_input_1, family = binomial(),
SL.library = c("SL.glm",learner_ranger$names ,learner_svm_rbf$names),
verbose = TRUE,cvControl=list(10,TRUE) ,control = list(TRUE, TRUE))
sl1
# previsioni VALIDATION SET
pred_rocr = ROCR::prediction(sl1$SL.predict, validation_output_1)
auc = ROCR::performance(pred_rocr, measure = "auc", x.measure = "cutoff")@y.values[[1]]
auc
#previsioni TEST SET
pred1 = predict(sl1, test_input_1, onlySL = TRUE)
pred_rocr = ROCR::prediction(pred1$pred, test_output_1)
auc = ROCR::performance(pred_rocr, measure = "auc", x.measure = "cutoff")@y.values[[1]]
auc
#monk 1
monk_train_1_hot = read.csv("./MONK/monk_1_train_hot.csv", header = FALSE)
#controllo se esistono valori NA
colSums(is.na(monk_train_1_hot))
# creo input - output train
set.seed(1)
split_id <- partition(monk_train_1_hot$V1, p = c(train = 0.7, valid = 0.3))
#monk 1
monk_train_1_hot = read.csv("./MONK/monk_1_train_hot.csv", header = FALSE)
#controllo se esistono valori NA
colSums(is.na(monk_train_1_hot))
# creo input - output train
set.seed(1)
split_id <- partition(monk_train_1_hot$V1, p = c(train = 0.7, valid = 0.3))
library(corrplot)
library(ggplot2)
library(SuperLearner)
library(dplyr)                      # For the "filter" function
library(splitTools)                 # For the "partition" function
library(caret)
library(performanceEstimation)
library(ggm)
library(MLmetrics)
#monk 1
monk_train_1_hot = read.csv("./MONK/monk_1_train_hot.csv", header = FALSE)
#controllo se esistono valori NA
colSums(is.na(monk_train_1_hot))
# creo input - output train
set.seed(1)
split_id <- partition(monk_train_1_hot$V1, p = c(train = 0.7, valid = 0.3))
train_output_1 = monk_train_1_hot[split_id$train,1]
train_input_1 = monk_train_1_hot[split_id$train,-1]
validation_input_1 = monk_train_1_hot[split_id$valid,-1]
validation_output_1 = monk_train_1_hot[split_id$valid,1]
# creo input - output test
monk_test_1_hot = read.csv("./MONK/monk_1_test_hot.csv", header = FALSE)
colSums(is.na((monk_test_1_hot)))
test_output_1 = monk_test_1_hot$V1
test_input_1 = subset(monk_test_1_hot,select = -V1)
#provo SuperLearner, se aggiungo SL.knn da errore durante le previsioni
#setto seme per riprodurre la CV ogni volta
#provare a vedere se si può cambiare iperparametri, es KSVM (vedi slide 9 SVM-other-info)
set.seed(3)
tune_ranger = list(num.trees = c(500,1000,2000),
mtry = c(floor(sqrt(ncol(train_input_1))),ncol(train_input_1)))
learner_ranger = create.Learner("SL.ranger", tune = tune_ranger, detailed_names = TRUE, name_prefix = "ranger")
tune_svm_rbf = list(kernel = "rbfdot", sigma = c(0.06, 0.01, 0.1), C = c(0.8, 1, 1.2))
learner_svm_rbf = create.Learner("SL.ksvm", tune = tune_svm_rbf, detailed_names = TRUE, name_prefix = "ksvm")
sl1 <- SuperLearner(Y = train_output_1, X = train_input_1, newX = validation_input_1, family = binomial(),
SL.library = c("SL.glm",learner_ranger$names ,learner_svm_rbf$names),
verbose = TRUE,cvControl=list(10,TRUE) ,control = list(TRUE, TRUE))
sl1
# previsioni VALIDATION SET
pred_rocr = ROCR::prediction(sl1$SL.predict, validation_output_1)
auc = ROCR::performance(pred_rocr, measure = "auc", x.measure = "cutoff")@y.values[[1]]
auc
#previsioni TEST SET
pred1 = predict(sl1, test_input_1, onlySL = TRUE)
pred_rocr = ROCR::prediction(pred1$pred, test_output_1)
auc = ROCR::performance(pred_rocr, measure = "auc", x.measure = "cutoff")@y.values[[1]]
auc
#monk 2
monk_train_2_hot=read.csv("./MONK/monk_2_train_hot.csv",header = FALSE)
colSums(is.na(monk_train_2_hot))
set.seed(1)
split_id <- partition(monk_train_2_hot$V1, p = c(train = 0.7, valid = 0.3))
train_output_2 = monk_train_2_hot[split_id$train,1]
train_input_2 = monk_train_2_hot[split_id$train,-1]
validation_input_2 = monk_train_2_hot[split_id$valid,-1]
validation_output_2 = monk_train_2_hot[split_id$valid,1]
monk_test_2_hot = read.csv("./MONK/monk_2_test_hot.csv",header = FALSE)
test_output_2 = monk_test_2_hot$V1
test_input_2 = subset(monk_test_2_hot,select = -V1)
set.seed(1)
sl2 <- SuperLearner(Y = train_output_2, X = train_input_2, newX = validation_input_2,family = binomial(),
SL.library = c("SL.glm",learner_ranger$names,learner_svm_rbf$names),
verbose = TRUE, cvControl=list(10,TRUE),control = list(TRUE, TRUE))
sl2
# previsioni VALIDATION SET
pred_rocr = ROCR::prediction(sl2$SL.predict, validation_output_2)
auc = ROCR::performance(pred_rocr, measure = "auc", x.measure = "cutoff")@y.values[[1]]
auc
# previsioni TEST SET
pred2 = predict(sl2, test_input_2, onlySL = TRUE)
pred_rocr = ROCR::prediction(pred2$pred, test_output_2)
auc = ROCR::performance(pred_rocr, measure = "auc", x.measure = "cutoff")@y.values[[1]]
auc
#monk3
monk_train_3_hot=read.csv("./MONK/monk_3_train_hot.csv",header = FALSE)
set.seed(1)
split_id <- partition(monk_train_3_hot$V1, p = c(train = 0.7, valid = 0.3))
train_output_3 = monk_train_3_hot[split_id$train,1]
train_input_3 = monk_train_3_hot[split_id$train,-1]
validation_input_3 = monk_train_3_hot[split_id$valid,-1]
validation_output_3 = monk_train_3_hot[split_id$valid,1]
monk_test_3_hot = read.csv("./MONK/monk_3_test_hot.csv",header = FALSE)
test_output_3 = monk_test_3_hot$V1
test_input_3 = subset(monk_test_3_hot,select = -V1)
sl3 <- SuperLearner(Y = train_output_3, X = train_input_3, newX = validation_input_3,family = binomial(),
SL.library = c("SL.glm",learner_ranger$names,learner_svm_rbf$names),
verbose = TRUE, cvControl=list(10,TRUE),control = list(TRUE, TRUE))
sl3
#previsioni VALIDATION SET
pred_rocr = ROCR::prediction(sl3$SL.predict, validation_output_3)
auc = ROCR::performance(pred_rocr, measure = "auc", x.measure = "cutoff")@y.values[[1]]
auc
#previsioni TEST SET
pred3 = predict(sl3, test_input_3, onlySL = TRUE)
pred_rocr = ROCR::prediction(pred3$pred, test_output_3)
auc = ROCR::performance(pred_rocr, measure = "auc", x.measure = "cutoff")@y.values[[1]]
auc
#CUP
cup_train = read.csv("./CUP/ML-CUP22-TR", header = TRUE)
#CUP
cup_train = read.csv("./CUP/ML-CUP22-TR.csv", header = TRUE)
#controllo se esistono valori NA
colSums(is.na(cup_train))
#controllo se esistono valori NA
colSums(is.na(monk_train_1_hot))
#CUP
cup_train = read.csv("./CUP/ML-CUP22-TR_noHeader.csv", header = FALSE)
#controllo se esistono valori NA
colSums(is.na(cup_train))
#CUP
cup_train = read.csv("./CUP/ML-CUP22-TR_noHeader.csv", header = FALSE)
cup_train = cup_train[c(2,)]
cup_train = cup_train[c(2, 12)]
#CUP
cup_train = read.csv("./CUP/ML-CUP22-TR_noHeader.csv", header = FALSE)
cup_train = cup_train[c(2 - 12)]
#CUP
cup_train = read.csv("./CUP/ML-CUP22-TR_noHeader.csv", header = FALSE)
cup_train = cup_train[c(-1)]
#controllo se esistono valori NA
colSums(is.na(cup_train))
# creo input - output train
monk_train_1_hot$V1
# creo input - output train
set.seed(1)
split_id <- partition(cup_train$V2, p = c(train = 0.7, valid = 0.3))
split_id
cup_train$V2
train_input = cup_train[split_id$train,-1]
train_output_1 = cup_train[split_id$train, 11]
train_output_2 = cup_train[split_id$train, 12]
validation_input = cup_train[split_id$valid,-1]
validation_output_1 = cup_train[split_id$valid,11]
validation_output_2 = cup_train[split_id$valid,12]
train_input
train_input = cup_train[split_id$train,-11, -12]
train_input
train_input = cup_train[split_id$train, -c(11,12)]
train_input
train_input = cup_train[split_id$train, -c(11, -12)]
train_input
train_input = cup_train[split_id$train, -c(11, -12)]
train_input = cup_train[split_id$train, c(-11, -12)]
train_input
train_input = cup_train[split_id$train, -11]
train_input
train_input = cup_train[split_id$train, -1]
train_input
train_input = cup_train[split_id$train, c(-10, -11)]
train_input
train_output_1 = cup_train[split_id$train, 11]
train_output_2 = cup_train[split_id$train, 12]
train_output_1
View(cup_train)
train_output_1 = cup_train[split_id$train, 10]
train_output_2 = cup_train[split_id$train, 11]
train_output_1
train_output_2
validation_input = cup_train[split_id$valid, c(-10, -11)]
validation_output_1 = cup_train[split_id$valid,10]
validation_output_2 = cup_train[split_id$valid,11]
train_input
train_output_1
train_output_2
#provo SuperLearner, se aggiungo SL.knn da errore durante le previsioni
#setto seme per riprodurre la CV ogni volta
#provare a vedere se si può cambiare iperparametri, es KSVM (vedi slide 9 SVM-other-info)
set.seed(3)
tune_ranger = list(num.trees = c(500,1000,2000),
mtry = c(floor(sqrt(ncol(train_input_1))),ncol(train_input_1)))
learner_ranger = create.Learner("SL.ranger", tune = tune_ranger, detailed_names = TRUE, name_prefix = "ranger")
tune_svm_rbf = list(kernel = "rbfdot", sigma = c(0.06, 0.01, 0.1), C = c(0.8, 1, 1.2))
learner_svm_rbf = create.Learner("SL.ksvm", tune = tune_svm_rbf, detailed_names = TRUE, name_prefix = "ksvm")
sl1 <- SuperLearner(Y = train_output_1, X = train_input_1, newX = validation_input_1, family = binomial(),
SL.library = c("SL.glm",learner_ranger$names ,learner_svm_rbf$names),
verbose = TRUE,cvControl=list(10,TRUE) ,control = list(TRUE, TRUE))
sl1 <- SuperLearner(Y = train_output_1, X = train_input_1, newX = validation_input_1, family = binomial(),
SL.library = c("SL.glm",learner_ranger$names ,learner_svm_rbf$names),
verbose = TRUE,cvControl=list(10,TRUE) ,control = list(TRUE, TRUE))
#provo SuperLearner, se aggiungo SL.knn da errore durante le previsioni
#setto seme per riprodurre la CV ogni volta
#provare a vedere se si può cambiare iperparametri, es KSVM (vedi slide 9 SVM-other-info)
set.seed(3)
tune_ranger = list(num.trees = c(500,1000,2000),
mtry = c(floor(sqrt(ncol(train_input_1))),ncol(train_input_1)))
learner_ranger = create.Learner("SL.ranger", tune = tune_ranger, detailed_names = TRUE, name_prefix = "ranger")
tune_svm_rbf = list(kernel = "rbfdot", sigma = c(0.06, 0.01, 0.1), C = c(0.8, 1, 1.2))
learner_svm_rbf = create.Learner("SL.ksvm", tune = tune_svm_rbf, detailed_names = TRUE, name_prefix = "ksvm")
sl1 <- SuperLearner(Y = train_output_1, X = train_input_1, newX = validation_input_1, family = binomial(),
SL.library = c("SL.glm",learner_ranger$names ,learner_svm_rbf$names),
verbose = TRUE,cvControl=list(10,TRUE) ,control = list(TRUE, TRUE))
#monk 1
monk_train_1_hot = read.csv("./MONK/monk_1_train_hot.csv", header = FALSE)
#controllo se esistono valori NA
colSums(is.na(monk_train_1_hot))
# creo input - output train
set.seed(1)
split_id <- partition(monk_train_1_hot$V1, p = c(train = 0.7, valid = 0.3))
train_output_1 = monk_train_1_hot[split_id$train,1]
train_input_1 = monk_train_1_hot[split_id$train,-1]
validation_input_1 = monk_train_1_hot[split_id$valid,-1]
validation_output_1 = monk_train_1_hot[split_id$valid,1]
# creo input - output test
monk_test_1_hot = read.csv("./MONK/monk_1_test_hot.csv", header = FALSE)
colSums(is.na((monk_test_1_hot)))
test_output_1 = monk_test_1_hot$V1
test_input_1 = subset(monk_test_1_hot,select = -V1)
#provo SuperLearner, se aggiungo SL.knn da errore durante le previsioni
#setto seme per riprodurre la CV ogni volta
#provare a vedere se si può cambiare iperparametri, es KSVM (vedi slide 9 SVM-other-info)
set.seed(3)
tune_ranger = list(num.trees = c(500,1000,2000),
mtry = c(floor(sqrt(ncol(train_input_1))),ncol(train_input_1)))
learner_ranger = create.Learner("SL.ranger", tune = tune_ranger, detailed_names = TRUE, name_prefix = "ranger")
tune_svm_rbf = list(kernel = "rbfdot", sigma = c(0.06, 0.01, 0.1), C = c(0.8, 1, 1.2))
learner_svm_rbf = create.Learner("SL.ksvm", tune = tune_svm_rbf, detailed_names = TRUE, name_prefix = "ksvm")
sl1 <- SuperLearner(Y = train_output_1, X = train_input_1, newX = validation_input_1, family = binomial(),
SL.library = c("SL.glm",learner_ranger$names ,learner_svm_rbf$names),
verbose = TRUE,cvControl=list(10,TRUE) ,control = list(TRUE, TRUE))
sl1
#CUP
cup_train = read.csv("./CUP/ML-CUP22-TR_noHeader.csv", header = FALSE)
cup_train = cup_train[c(-1)]
#controllo se esistono valori NA
colSums(is.na(cup_train))
# creo input - output train
set.seed(1)
split_id_cup <- partition(cup_train$V2, p = c(train = 0.7, valid = 0.3))
train_input_cup = cup_train[split_id_cup$train, c(-10, -11)]
train_output_1_cup = cup_train[split_id_cup$train, 10]
train_output_2_cup = cup_train[split_id_cup$train, 11]
validation_input_cup = cup_train[split_id_cup$valid, c(-10, -11)]
validation_output_1_cup = cup_train[split_id_cup$valid,10]
validation_output_2_cup = cup_train[split_id_cup$valid,11]
#Superlearner
set.seed(3)
tune_ranger_cup = list(num.trees = c(500,1000,2000), mtry = c(floor(sqrt(ncol(train_input_cup))), ncol(train_input_cup)))
learner_ranger_cup = create.Learner("SL.ranger", tune = tune_ranger_cup, detailed_names = TRUE, name_prefix = "ranger")
tune_svm_rbf_cup = list(kernel = "rbfdot", sigma = c(0.06, 0.01, 0.1), C = c(0.8, 1, 1.2))
learner_svm_rbf_cup = create.Learner("SL.ksvm", tune = tune_svm_rbf_cup, detailed_names = TRUE, name_prefix = "ksvm")
sl_cup_1 <- SuperLearner(Y = train_output_1_cup, X = train_input_cup, newX = validation_input_cup, family = gaussian(),
SL.library = c(learner_ranger_cup$names ,learner_svm_rbf_cup$names),
verbose = TRUE, cvControl = list(10, TRUE), control = list(TRUE, TRUE))
sl_cup_1 <- SuperLearner(Y = train_output_1_cup, X = train_input_cup, newX = validation_input_cup, family = gaussian(),
SL.library = c(learner_ranger_cup$names ,learner_svm_rbf_cup$names),
verbose = TRUE, cvControl = list(10, FALSE), control = list(TRUE, TRUE))
sl_cup_1
# previsioni VALIDATION SET
pred_rocr_cup = ROCR::prediction(sl_cup_1$SL.predict, validation_output_1_cup)
# previsioni VALIDATION SET
pred_cup = predict.SuperLearner(sl_cup_1, validation_input_cup, onlySL = TRUE)
pred_cup
validation_input_cup
predict.SuperLearner
# previsioni VALIDATION SET
pred_cup = predict.SuperLearner(object = sl_cup_1, newdata = validation_input_cup, onlySL = TRUE)
pred_cup
pred_cup.pred
pred_cup$pred
View(validation_input)
View(validation_input_cup)
#CUP
cup_train = read.csv("./CUP/ML-CUP22-TR_noHeader.csv", header = FALSE)
cup_train = cup_train[c(-1)]
#controllo se esistono valori NA
colSums(is.na(cup_train))
# creo input - output train
set.seed(1)
split_id_cup <- partition(cup_train$V2, p = c(train = 0.7, valid = 0.3))
train_input_cup = cup_train[split_id_cup$train, c(-10, -11)]
train_output_1_cup = cup_train[split_id_cup$train, 10]
train_output_2_cup = cup_train[split_id_cup$train, 11]
validation_input_cup = cup_train[split_id_cup$valid, c(-10, -11)]
validation_output_1_cup = cup_train[split_id_cup$valid,10]
validation_output_2_cup = cup_train[split_id_cup$valid,11]
#Superlearner
set.seed(3)
tune_ranger_cup = list(num.trees = c(500,1000,2000), mtry = c(floor(sqrt(ncol(train_input_cup))), ncol(train_input_cup)))
learner_ranger_cup = create.Learner("SL.ranger", tune = tune_ranger_cup, detailed_names = TRUE, name_prefix = "ranger")
tune_svm_rbf_cup = list(kernel = "rbfdot", sigma = c(0.06, 0.01, 0.1), C = c(0.8, 1, 1.2))
learner_svm_rbf_cup = create.Learner("SL.ksvm", tune = tune_svm_rbf_cup, detailed_names = TRUE, name_prefix = "ksvm")
sl_cup_1 <- SuperLearner(Y = train_output_1_cup, X = train_input_cup, newX = validation_input_cup, family = gaussian(),
SL.library = c(learner_ranger_cup$names ,learner_svm_rbf_cup$names),
verbose = TRUE, cvControl = list(10, FALSE), control = list(TRUE, TRUE))
sl_cup_1
# previsioni VALIDATION SET
pred_cup = predict.SuperLearner(object = sl_cup_1, newdata = validation_input_cup, onlySL = TRUE)
pred_cup$pred
differences[length(validation_output_1_cup)] = {0}
for(i in 1:length(validation_output_1_cup)) {
differences[i] = abs(validation_output_1_cup[i] - pred_cup$pred[i])
}
differences <- array(dim = c(length(validation_output_1_cup), 1))
for(i in 1:length(validation_output_1_cup)) {
differences[i] = abs(validation_output_1_cup[i] - pred_cup$pred[i])
}
differences
#input1
sl_cup_1 <- SuperLearner(Y = train_output_1_cup, X = train_input_cup, newX = validation_input_cup, family = gaussian(),
SL.library = c(learner_ranger_cup$names ,learner_svm_rbf_cup$names),
verbose = TRUE, cvControl = list(10, FALSE), control = list(TRUE, TRUE))
# creo input - output train
set.seed(1)
split_id_cup <- partition(cup_train$V2, p = c(train = 0.7, valid = 0.3))
train_input_cup = cup_train[split_id_cup$train, c(-10, -11)]
train_output_1_cup = cup_train[split_id_cup$train, 10]
train_output_2_cup = cup_train[split_id_cup$train, 11]
validation_input_cup = cup_train[split_id_cup$valid, c(-10, -11)]
validation_output_1_cup = cup_train[split_id_cup$valid,10]
validation_output_2_cup = cup_train[split_id_cup$valid,11]
#Superlearner
set.seed(3)
tune_ranger_cup = list(num.trees = c(500,1000,2000), mtry = c(floor(sqrt(ncol(train_input_cup))), ncol(train_input_cup)))
learner_ranger_cup = create.Learner("SL.ranger", tune = tune_ranger_cup, detailed_names = TRUE, name_prefix = "ranger")
tune_svm_rbf_cup = list(kernel = "rbfdot", sigma = c(0.06, 0.01, 0.1), C = c(0.8, 1, 1.2))
learner_svm_rbf_cup = create.Learner("SL.ksvm", tune = tune_svm_rbf_cup, detailed_names = TRUE, name_prefix = "ksvm")
#input1
sl_cup_1 <- SuperLearner(Y = train_output_1_cup, X = train_input_cup, newX = validation_input_cup, family = gaussian(),
SL.library = c(learner_ranger_cup$names ,learner_svm_rbf_cup$names),
verbose = TRUE, cvControl = list(10, FALSE), control = list(TRUE, TRUE))
sl_cup_1
#input2
sl_cup_2 <- SuperLearner(Y = train_output_2_cup, X = train_input_cup, newX = validation_input_cup, family = gaussian(),
SL.library = c(learner_ranger_cup$names ,learner_svm_rbf_cup$names),
verbose = TRUE, cvControl = list(10, FALSE), control = list(TRUE, TRUE))
sl_cup_2
# previsioni VALIDATION SET
pred_cup_1 = predict.SuperLearner(object = sl_cup_1, newdata = validation_input_cup, onlySL = TRUE)
pred_cup_2 = predict.SuperLearner(object = sl_cup_2, newdata = validation_input_cup, onlySL = TRUE)
# previsioni VALIDATION SET
pred_cup_1 = predict.SuperLearner(object = sl_cup_1, newdata = validation_input_cup, onlySL = TRUE)
pred_cup_2 = predict.SuperLearner(object = sl_cup_2, newdata = validation_input_cup, onlySL = TRUE)
mae1 = MAE(pred_cup_1$pred)
mae1 = MAE(pred_cup_1$pred, validation_output_1_cup)
mae2 = MAE(pred_cup_2$pred, validation_output_2_cup)
mae1
mae2
mean(validation_output_1_cup)
abs(mean(validation_output_2_cup))
accuracy1 = mae1 / mean(validation_output_1_cup)
accuracy2 = mae2 / abs(mean(validation_output_2_cup))
accuracy1
accuracy2
accuracy1 = 100 - (mae1 / mean(validation_output_1_cup))
accuracy2 = 100 - (mae2 / abs(mean(validation_output_2_cup)))
accuracy1
accuracy2
#CUP
cup_train = read.csv("./CUP/ML-CUP22-TR_noHeader.csv", header = FALSE)
cup_train = cup_train[c(-1)]
#controllo se esistono valori NA
colSums(is.na(cup_train))
# creo input - output train
set.seed(1)
split_id_cup <- partition(cup_train$V2, p = c(train = 0.7, valid = 0.3))
library(MLmetrics)
split_id_cup <- partition(cup_train$V2, p = c(train = 0.7, valid = 0.3))
library(MLmetrics)
library(performanceEstimation)
library(splitTools)
# creo input - output train
set.seed(1)
split_id_cup <- partition(cup_train$V2, p = c(train = 0.7, valid = 0.3))
train_input_cup = cup_train[split_id_cup$train, c(-10, -11)]
train_output_1_cup = cup_train[split_id_cup$train, 10]
train_output_2_cup = cup_train[split_id_cup$train, 11]
validation_input_cup = cup_train[split_id_cup$valid, c(-10, -11)]
validation_output_1_cup = cup_train[split_id_cup$valid,10]
validation_output_2_cup = cup_train[split_id_cup$valid,11]
#Superlearner
set.seed(3)
tune_ranger_cup = list(num.trees = c(500,1000,2000), mtry = c(floor(sqrt(ncol(train_input_cup))), ncol(train_input_cup)))
learner_ranger_cup = create.Learner("SL.ranger", tune = tune_ranger_cup, detailed_names = TRUE, name_prefix = "ranger")
tune_ranger_cup = list(num.trees = c(500,1000,2000), mtry = c(floor(sqrt(ncol(train_input_cup))), ncol(train_input_cup)))
learner_ranger_cup = create.Learner("SL.ranger", tune = tune_ranger_cup, detailed_names = TRUE, name_prefix = "ranger")
library(SuperLearner)
tune_ranger_cup = list(num.trees = c(500,1000,2000), mtry = c(floor(sqrt(ncol(train_input_cup))), ncol(train_input_cup)))
learner_ranger_cup = create.Learner("SL.ranger", tune = tune_ranger_cup, detailed_names = TRUE, name_prefix = "ranger")
tune_svm_rbf_cup = list(kernel = "rbfdot", sigma = c(0.06, 0.01, 0.1), C = c(0.8, 1, 1.2))
learner_svm_rbf_cup = create.Learner("SL.ksvm", tune = tune_svm_rbf_cup, detailed_names = TRUE, name_prefix = "ksvm")
#input1
sl_cup_1 <- SuperLearner(Y = train_output_1_cup, X = train_input_cup, newX = validation_input_cup, family = gaussian(),
SL.library = c(learner_ranger_cup$names ,learner_svm_rbf_cup$names),
verbose = TRUE, cvControl = list(10, FALSE), control = list(TRUE, TRUE))
sl_cup_1
#input2
sl_cup_2 <- SuperLearner(Y = train_output_2_cup, X = train_input_cup, newX = validation_input_cup, family = gaussian(),
SL.library = c(learner_ranger_cup$names ,learner_svm_rbf_cup$names),
verbose = TRUE, cvControl = list(10, FALSE), control = list(TRUE, TRUE))
sl_cup_2
# previsioni VALIDATION SET
pred_cup_1 = predict.SuperLearner(object = sl_cup_1, newdata = validation_input_cup, onlySL = TRUE)
pred_cup_2 = predict.SuperLearner(object = sl_cup_2, newdata = validation_input_cup, onlySL = TRUE)
mae1 = MAE(pred_cup_1$pred, validation_output_1_cup)
mae2 = MAE(pred_cup_2$pred, validation_output_2_cup)
accuracy1 = 100 - (mae1 / mean(validation_output_1_cup))
accuracy2 = 100 - (mae2 / abs(mean(validation_output_2_cup)))
accuracy1
accuracy2
