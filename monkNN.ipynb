{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabena98/ML_project/blob/main/Copia_di_ml_project_unipi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSyUQoGlkkmO",
        "outputId": "01a0ba3f-89fd-4ed4-bab2-62a2d23a0a0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.10.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.8/dist-packages (from scikeras) (21.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=0.21->scikeras) (3.0.9)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srhrql8hkFF6",
        "outputId": "0c23964a-bc12-412b-9fb0-e7a34a993465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bayesian-optimization\n",
            "  Downloading bayesian_optimization-1.4.2-py3-none-any.whl (17 kB)\n",
            "Collecting colorama>=0.4.6\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from bayesian-optimization) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.1.0)\n",
            "Installing collected packages: colorama, bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.4.2 colorama-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZRJmPJXOBiC",
        "outputId": "5c9ec769-b6bd-45a5-a928-cbd0c731e705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2hShIS2xb7mR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import math\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.layers import LeakyReLU\n",
        "LeakyReLU = LeakyReLU(alpha=0.1)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNCwtprTsD-E"
      },
      "outputs": [],
      "source": [
        "# Make scorer accuracy\n",
        "score_acc = make_scorer(accuracy_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "puyVsRp9cEvp"
      },
      "outputs": [],
      "source": [
        "# load the dataset\n",
        "monks_1_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MONK/monk_1_train_hot.csv',\n",
        "                            names=[\"y\", \"x1_1\", \"x1_2\", \"x1_3\", \"x2_1\", \"x2_2\", \"x2_3\", \"x3_1\", \"x3_2\", \"x4_1\", \"x4_2\", \"x4_3\", \"x5_1\", \"x5_2\", \"x5_3\", \"x5_4\", \"x6_1\", \"x6_2\"])\n",
        "monks_2_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MONK/monk_2_train_hot.csv',\n",
        "                            names=[\"y\", \"x1_1\", \"x1_2\", \"x1_3\", \"x2_1\", \"x2_2\", \"x2_3\", \"x3_1\", \"x3_2\", \"x4_1\", \"x4_2\", \"x4_3\", \"x5_1\", \"x5_2\", \"x5_3\", \"x5_4\", \"x6_1\", \"x6_2\"])\n",
        "monks_3_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MONK/monk_3_train_hot.csv',\n",
        "                            names=[\"y\", \"x1_1\", \"x1_2\", \"x1_3\", \"x2_1\", \"x2_2\", \"x2_3\", \"x3_1\", \"x3_2\", \"x4_1\", \"x4_2\", \"x4_3\", \"x5_1\", \"x5_2\", \"x5_3\", \"x5_4\", \"x6_1\", \"x6_2\"])\n",
        "monks_1_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MONK/monk_1_test_hot.csv',\n",
        "                           names=[\"y\", \"x1_1\", \"x1_2\", \"x1_3\", \"x2_1\", \"x2_2\", \"x2_3\", \"x3_1\", \"x3_2\", \"x4_1\", \"x4_2\", \"x4_3\", \"x5_1\", \"x5_2\", \"x5_3\", \"x5_4\", \"x6_1\", \"x6_2\"])\n",
        "monks_2_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MONK/monk_2_test_hot.csv',\n",
        "                           names=[\"y\", \"x1_1\", \"x1_2\", \"x1_3\", \"x2_1\", \"x2_2\", \"x2_3\", \"x3_1\", \"x3_2\", \"x4_1\", \"x4_2\", \"x4_3\", \"x5_1\", \"x5_2\", \"x5_3\", \"x5_4\", \"x6_1\", \"x6_2\"])\n",
        "monks_3_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/MONK/monk_3_test_hot.csv', \n",
        "                           names=[\"y\", \"x1_1\", \"x1_2\", \"x1_3\", \"x2_1\", \"x2_2\", \"x2_3\", \"x3_1\", \"x3_2\", \"x4_1\", \"x4_2\", \"x4_3\", \"x5_1\", \"x5_2\", \"x5_3\", \"x5_4\", \"x6_1\", \"x6_2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qnPjjphyRlF-",
        "outputId": "2e4c5add-fa99-4ec7-d170-4c9f4822d516"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-94c5ee3c-13bc-4c80-b3f7-1618ae71e3a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>x1_1</th>\n",
              "      <th>x1_2</th>\n",
              "      <th>x1_3</th>\n",
              "      <th>x2_1</th>\n",
              "      <th>x2_2</th>\n",
              "      <th>x2_3</th>\n",
              "      <th>x3_1</th>\n",
              "      <th>x3_2</th>\n",
              "      <th>x4_1</th>\n",
              "      <th>x4_2</th>\n",
              "      <th>x4_3</th>\n",
              "      <th>x5_1</th>\n",
              "      <th>x5_2</th>\n",
              "      <th>x5_3</th>\n",
              "      <th>x5_4</th>\n",
              "      <th>x6_1</th>\n",
              "      <th>x6_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>124 rows Ã— 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94c5ee3c-13bc-4c80-b3f7-1618ae71e3a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94c5ee3c-13bc-4c80-b3f7-1618ae71e3a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94c5ee3c-13bc-4c80-b3f7-1618ae71e3a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       y  x1_1  x1_2  x1_3  x2_1  x2_2  x2_3  x3_1  x3_2  x4_1  x4_2  x4_3  \\\n",
              "0    1.0   1.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0   \n",
              "1    1.0   1.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0   \n",
              "2    1.0   1.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0   \n",
              "3    1.0   1.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0   \n",
              "4    1.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0   1.0   1.0   0.0   0.0   \n",
              "..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
              "119  1.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   1.0   1.0   0.0   0.0   \n",
              "120  1.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0   1.0   \n",
              "121  1.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0   1.0   \n",
              "122  1.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0   1.0   \n",
              "123  1.0   0.0   0.0   1.0   0.0   0.0   1.0   0.0   1.0   0.0   0.0   1.0   \n",
              "\n",
              "     x5_1  x5_2  x5_3  x5_4  x6_1  x6_2  \n",
              "0     0.0   0.0   1.0   0.0   1.0   0.0  \n",
              "1     0.0   0.0   1.0   0.0   0.0   1.0  \n",
              "2     0.0   1.0   0.0   0.0   1.0   0.0  \n",
              "3     0.0   0.0   1.0   0.0   0.0   1.0  \n",
              "4     0.0   1.0   0.0   0.0   1.0   0.0  \n",
              "..    ...   ...   ...   ...   ...   ...  \n",
              "119   0.0   0.0   0.0   1.0   0.0   1.0  \n",
              "120   1.0   0.0   0.0   0.0   0.0   1.0  \n",
              "121   0.0   1.0   0.0   0.0   0.0   1.0  \n",
              "122   0.0   0.0   1.0   0.0   0.0   1.0  \n",
              "123   0.0   0.0   0.0   1.0   0.0   1.0  \n",
              "\n",
              "[124 rows x 18 columns]"
            ]
          },
          "execution_count": 214,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "monks_1_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG3REXB6djMm"
      },
      "source": [
        "# **Nuovo input**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "EE4Z2KMd_hLw"
      },
      "outputs": [],
      "source": [
        "X_1_tr = monks_1_train.iloc[:,1:].values\n",
        "y_1_tr = monks_1_train.iloc[:,0].values\n",
        "\n",
        "X_2_tr = monks_2_train.iloc[:,1:].values\n",
        "y_2_tr = monks_2_train.iloc[:,0].values\n",
        "\n",
        "X_3_tr = monks_3_train.iloc[:,1:].values\n",
        "y_3_tr = monks_3_train.iloc[:,0].values\n",
        "\n",
        "X_test_1 = monks_1_test.iloc[:,1:].values\n",
        "y_test_1 = monks_1_test.iloc[:,0].values\n",
        "\n",
        "X_test_2 = monks_2_test.iloc[:,1:].values\n",
        "y_test_2 = monks_2_test.iloc[:,0].values\n",
        "\n",
        "X_test_3 = monks_3_test.iloc[:,1:].values\n",
        "y_test_3 = monks_3_test.iloc[:,0].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADKh4TVlgT2R"
      },
      "source": [
        "# **MONK 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rZGyh0SfgNl",
        "outputId": "e21a2fe9-6042-454e-99da-2ce33c850237"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "...\n",
        "# define the keras model for monk 1\n",
        "model_1 = Sequential()\n",
        "model_1.add(Dense(4, input_shape=(X_1_tr.shape[1],), activation='relu'))\n",
        "model_1.add(Dense(1, activation='sigmoid'))\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQouALYJhtAT",
        "outputId": "c0fbc4a3-979f-4d2c-e88c-c522a11c9cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 4)                 72        \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77\n",
            "Trainable params: 77\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "...\n",
        "# compile the keras model\n",
        "model_1.summary()\n",
        "opt = tf.keras.optimizers.experimental.SGD(0.02, momentum=0.09)\n",
        "model_1.compile(loss='mean_squared_error', optimizer = opt, metrics=['accuracy'])\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXTlc8aQhtRT",
        "outputId": "2235530c-b926-4a97-f76c-1b9619a52ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.2441 - accuracy: 0.5484 - val_loss: 0.2471 - val_accuracy: 0.5741\n",
            "Epoch 2/150\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.2385 - accuracy: 0.6210 - val_loss: 0.2428 - val_accuracy: 0.5810\n",
            "Epoch 3/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.2319 - accuracy: 0.6371 - val_loss: 0.2382 - val_accuracy: 0.5949\n",
            "Epoch 4/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.2243 - accuracy: 0.6452 - val_loss: 0.2324 - val_accuracy: 0.6157\n",
            "Epoch 5/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.2154 - accuracy: 0.7016 - val_loss: 0.2254 - val_accuracy: 0.6389\n",
            "Epoch 6/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.2036 - accuracy: 0.7097 - val_loss: 0.2177 - val_accuracy: 0.6505\n",
            "Epoch 7/150\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.1910 - accuracy: 0.7419 - val_loss: 0.2082 - val_accuracy: 0.6759\n",
            "Epoch 8/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.1781 - accuracy: 0.7742 - val_loss: 0.1985 - val_accuracy: 0.7014\n",
            "Epoch 9/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.1665 - accuracy: 0.8065 - val_loss: 0.1901 - val_accuracy: 0.7315\n",
            "Epoch 10/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.1568 - accuracy: 0.7903 - val_loss: 0.1829 - val_accuracy: 0.7245\n",
            "Epoch 11/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.1464 - accuracy: 0.8306 - val_loss: 0.1791 - val_accuracy: 0.7477\n",
            "Epoch 12/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.1388 - accuracy: 0.8468 - val_loss: 0.1725 - val_accuracy: 0.7569\n",
            "Epoch 13/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.1318 - accuracy: 0.8468 - val_loss: 0.1690 - val_accuracy: 0.7639\n",
            "Epoch 14/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.1268 - accuracy: 0.8629 - val_loss: 0.1659 - val_accuracy: 0.7685\n",
            "Epoch 15/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.1223 - accuracy: 0.8629 - val_loss: 0.1638 - val_accuracy: 0.7685\n",
            "Epoch 16/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.1188 - accuracy: 0.8710 - val_loss: 0.1611 - val_accuracy: 0.7731\n",
            "Epoch 17/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.1149 - accuracy: 0.8790 - val_loss: 0.1582 - val_accuracy: 0.7755\n",
            "Epoch 18/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.1119 - accuracy: 0.8629 - val_loss: 0.1572 - val_accuracy: 0.7755\n",
            "Epoch 19/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.1084 - accuracy: 0.8710 - val_loss: 0.1514 - val_accuracy: 0.7731\n",
            "Epoch 20/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.1057 - accuracy: 0.8710 - val_loss: 0.1505 - val_accuracy: 0.7870\n",
            "Epoch 21/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.1017 - accuracy: 0.8790 - val_loss: 0.1440 - val_accuracy: 0.7894\n",
            "Epoch 22/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0994 - accuracy: 0.8790 - val_loss: 0.1406 - val_accuracy: 0.7917\n",
            "Epoch 23/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0958 - accuracy: 0.8710 - val_loss: 0.1371 - val_accuracy: 0.8032\n",
            "Epoch 24/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0940 - accuracy: 0.8790 - val_loss: 0.1340 - val_accuracy: 0.8171\n",
            "Epoch 25/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0899 - accuracy: 0.8871 - val_loss: 0.1347 - val_accuracy: 0.7986\n",
            "Epoch 26/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0872 - accuracy: 0.8952 - val_loss: 0.1264 - val_accuracy: 0.8403\n",
            "Epoch 27/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0849 - accuracy: 0.9032 - val_loss: 0.1231 - val_accuracy: 0.8495\n",
            "Epoch 28/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0822 - accuracy: 0.9113 - val_loss: 0.1189 - val_accuracy: 0.8611\n",
            "Epoch 29/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0792 - accuracy: 0.9194 - val_loss: 0.1153 - val_accuracy: 0.8657\n",
            "Epoch 30/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0759 - accuracy: 0.9113 - val_loss: 0.1129 - val_accuracy: 0.8634\n",
            "Epoch 31/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0731 - accuracy: 0.9194 - val_loss: 0.1069 - val_accuracy: 0.8796\n",
            "Epoch 32/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0695 - accuracy: 0.9194 - val_loss: 0.1022 - val_accuracy: 0.8935\n",
            "Epoch 33/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0659 - accuracy: 0.9274 - val_loss: 0.0966 - val_accuracy: 0.9097\n",
            "Epoch 34/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0625 - accuracy: 0.9355 - val_loss: 0.0933 - val_accuracy: 0.9120\n",
            "Epoch 35/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0590 - accuracy: 0.9274 - val_loss: 0.0879 - val_accuracy: 0.9120\n",
            "Epoch 36/150\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.0561 - accuracy: 0.9355 - val_loss: 0.0834 - val_accuracy: 0.9167\n",
            "Epoch 37/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0531 - accuracy: 0.9355 - val_loss: 0.0805 - val_accuracy: 0.9167\n",
            "Epoch 38/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0505 - accuracy: 0.9355 - val_loss: 0.0760 - val_accuracy: 0.9167\n",
            "Epoch 39/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0479 - accuracy: 0.9355 - val_loss: 0.0728 - val_accuracy: 0.9167\n",
            "Epoch 40/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0455 - accuracy: 0.9355 - val_loss: 0.0703 - val_accuracy: 0.9167\n",
            "Epoch 41/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0426 - accuracy: 0.9355 - val_loss: 0.0661 - val_accuracy: 0.9167\n",
            "Epoch 42/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0397 - accuracy: 0.9355 - val_loss: 0.0658 - val_accuracy: 0.9213\n",
            "Epoch 43/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0392 - accuracy: 0.9516 - val_loss: 0.0602 - val_accuracy: 0.9236\n",
            "Epoch 44/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0368 - accuracy: 0.9516 - val_loss: 0.0571 - val_accuracy: 0.9306\n",
            "Epoch 45/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0349 - accuracy: 0.9677 - val_loss: 0.0546 - val_accuracy: 0.9398\n",
            "Epoch 46/150\n",
            "124/124 [==============================] - 6s 48ms/step - loss: 0.0332 - accuracy: 0.9758 - val_loss: 0.0522 - val_accuracy: 0.9421\n",
            "Epoch 47/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9839 - val_loss: 0.0497 - val_accuracy: 0.9468\n",
            "Epoch 48/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0301 - accuracy: 0.9839 - val_loss: 0.0481 - val_accuracy: 0.9468\n",
            "Epoch 49/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0291 - accuracy: 0.9758 - val_loss: 0.0459 - val_accuracy: 0.9514\n",
            "Epoch 50/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.9839 - val_loss: 0.0447 - val_accuracy: 0.9514\n",
            "Epoch 51/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0269 - accuracy: 0.9839 - val_loss: 0.0425 - val_accuracy: 0.9560\n",
            "Epoch 52/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0256 - accuracy: 0.9839 - val_loss: 0.0410 - val_accuracy: 0.9560\n",
            "Epoch 53/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0247 - accuracy: 0.9839 - val_loss: 0.0396 - val_accuracy: 0.9560\n",
            "Epoch 54/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.0383 - val_accuracy: 0.9699\n",
            "Epoch 55/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0229 - accuracy: 0.9919 - val_loss: 0.0369 - val_accuracy: 0.9630\n",
            "Epoch 56/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0219 - accuracy: 0.9919 - val_loss: 0.0357 - val_accuracy: 0.9769\n",
            "Epoch 57/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0214 - accuracy: 0.9919 - val_loss: 0.0345 - val_accuracy: 0.9769\n",
            "Epoch 58/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.0334 - val_accuracy: 0.9769\n",
            "Epoch 59/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9792\n",
            "Epoch 60/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 0.9815\n",
            "Epoch 61/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 0.9884\n",
            "Epoch 62/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0294 - val_accuracy: 0.9884\n",
            "Epoch 63/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9884\n",
            "Epoch 64/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9884\n",
            "Epoch 65/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9907\n",
            "Epoch 66/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9884\n",
            "Epoch 67/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9931\n",
            "Epoch 68/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9954\n",
            "Epoch 69/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9931\n",
            "Epoch 70/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9931\n",
            "Epoch 71/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9954\n",
            "Epoch 72/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9954\n",
            "Epoch 73/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0221 - val_accuracy: 0.9954\n",
            "Epoch 74/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 0.9954\n",
            "Epoch 75/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0210 - val_accuracy: 0.9954\n",
            "Epoch 76/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9954\n",
            "Epoch 77/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 0.9954\n",
            "Epoch 78/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0199 - val_accuracy: 0.9954\n",
            "Epoch 79/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0191 - val_accuracy: 0.9954\n",
            "Epoch 80/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 0.9954\n",
            "Epoch 81/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9954\n",
            "Epoch 82/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0183 - val_accuracy: 0.9954\n",
            "Epoch 83/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0178 - val_accuracy: 0.9954\n",
            "Epoch 84/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9954\n",
            "Epoch 85/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9954\n",
            "Epoch 86/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9954\n",
            "Epoch 87/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9954\n",
            "Epoch 88/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9954\n",
            "Epoch 89/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0159 - val_accuracy: 0.9954\n",
            "Epoch 90/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0155 - val_accuracy: 0.9954\n",
            "Epoch 91/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9977\n",
            "Epoch 92/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0149 - val_accuracy: 0.9977\n",
            "Epoch 93/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 0.9977\n",
            "Epoch 94/150\n",
            "124/124 [==============================] - 2s 12ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 0.9954\n",
            "Epoch 95/150\n",
            "124/124 [==============================] - 2s 13ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0144 - val_accuracy: 0.9977\n",
            "Epoch 96/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 97/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
            "Epoch 98/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0136 - val_accuracy: 0.9977\n",
            "Epoch 99/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
            "Epoch 100/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
            "Epoch 101/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
            "Epoch 102/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 103/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9977\n",
            "Epoch 104/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
            "Epoch 105/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 106/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
            "Epoch 107/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 108/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 109/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 110/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 111/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 112/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 113/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
            "Epoch 114/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 115/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 116/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 117/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
            "Epoch 118/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
            "Epoch 119/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
            "Epoch 120/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 121/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 122/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 124/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 126/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 127/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 128/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 130/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "124/124 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 132/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 133/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 135/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 136/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
            "Epoch 137/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 139/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 142/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 143/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 144/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 145/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 146/150\n",
            "124/124 [==============================] - 1s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 147/150\n",
            "124/124 [==============================] - 1s 12ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
            "Epoch 148/150\n",
            "124/124 [==============================] - 2s 13ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 149/150\n",
            "124/124 [==============================] - 1s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 150/150\n",
            "124/124 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "CPU times: user 1min 54s, sys: 6.96 s, total: 2min 1s\n",
            "Wall time: 2min 22s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "# fit the keras model on the dataset\n",
        "history = model_1.fit(X_1_tr, y_1_tr,validation_data=(X_test_1,y_test_1) ,epochs=150, batch_size=1)\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbLDOj_ohtaT",
        "outputId": "43807cc4-7554-48d1-84ce-b54f4deb1010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9653\n",
            "Accuracy: 96.53\n"
          ]
        }
      ],
      "source": [
        "...\n",
        "# evaluate the keras model\n",
        "_, accuracy = model_1.evaluate(X_test_1, y_test_1, )\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "V6YMU-iIhteR",
        "outputId": "84edd486-ffa2-4274-967e-2486159b19b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 1.0000 Test: 1.0000\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Evaluate model\n",
        "from matplotlib import pyplot\n",
        "_, train_mse = model_1.evaluate(X_1_tr, y_1_tr, verbose=0)\n",
        "_, test_mse = model_1.evaluate(X_test_1,y_test_1,verbose=0)\n",
        "print('Train: %.4f Test: %.4f'%(train_mse,test_mse))\n",
        "pyplot.title('Loss / Mean Squared Error')\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.ylabel('accuracy')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yGqcPVFhthY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_-IyJZbgOH8"
      },
      "source": [
        "# **MONK 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tv3vJ0Jq6Hy",
        "outputId": "4f464883-85d8-4995-d14d-0626d002e93f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "...\n",
        "# define the keras model for monk 2\n",
        "model_2 = Sequential()\n",
        "model_2.add(Dense(4, input_shape=(X_test_2.shape[1],), activation='relu'))\n",
        "model_2.add(Dense(1, activation='sigmoid'))\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf36cJQEq6H4",
        "outputId": "6939a456-64a5-4e6d-bb14-4a12fd54f212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_22 (Dense)            (None, 4)                 72        \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77\n",
            "Trainable params: 77\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "...\n",
        "# compile the keras model\n",
        "model_2.summary()\n",
        "opt = tf.keras.optimizers.experimental.SGD(learning_rate = 0.05, momentum=0.09)\n",
        "model_2.compile(loss='mean_squared_error', optimizer = opt, metrics=['accuracy'])\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xcs8Lm66q6H5",
        "outputId": "8ba5dd6c-4786-4ad8-ef37-44769223e121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "169/169 [==============================] - 1s 6ms/step - loss: 0.2454 - accuracy: 0.6154 - val_loss: 0.2271 - val_accuracy: 0.6736\n",
            "Epoch 2/150\n",
            "169/169 [==============================] - 1s 6ms/step - loss: 0.2390 - accuracy: 0.6095 - val_loss: 0.2242 - val_accuracy: 0.6782\n",
            "Epoch 3/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.2339 - accuracy: 0.6213 - val_loss: 0.2220 - val_accuracy: 0.6782\n",
            "Epoch 4/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.2291 - accuracy: 0.6627 - val_loss: 0.2161 - val_accuracy: 0.6736\n",
            "Epoch 5/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.2236 - accuracy: 0.6272 - val_loss: 0.2134 - val_accuracy: 0.6875\n",
            "Epoch 6/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.2155 - accuracy: 0.6509 - val_loss: 0.2077 - val_accuracy: 0.6898\n",
            "Epoch 7/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.2057 - accuracy: 0.6509 - val_loss: 0.1992 - val_accuracy: 0.6875\n",
            "Epoch 8/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.1937 - accuracy: 0.7160 - val_loss: 0.1841 - val_accuracy: 0.7083\n",
            "Epoch 9/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.1774 - accuracy: 0.7278 - val_loss: 0.1694 - val_accuracy: 0.7639\n",
            "Epoch 10/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.1613 - accuracy: 0.8225 - val_loss: 0.1518 - val_accuracy: 0.8009\n",
            "Epoch 11/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.1436 - accuracy: 0.8343 - val_loss: 0.1343 - val_accuracy: 0.8519\n",
            "Epoch 12/150\n",
            "169/169 [==============================] - 1s 8ms/step - loss: 0.1256 - accuracy: 0.8580 - val_loss: 0.1224 - val_accuracy: 0.8588\n",
            "Epoch 13/150\n",
            "169/169 [==============================] - 1s 7ms/step - loss: 0.1080 - accuracy: 0.9112 - val_loss: 0.1008 - val_accuracy: 0.9236\n",
            "Epoch 14/150\n",
            "169/169 [==============================] - 1s 7ms/step - loss: 0.0877 - accuracy: 0.9527 - val_loss: 0.0807 - val_accuracy: 0.9722\n",
            "Epoch 15/150\n",
            "169/169 [==============================] - 1s 6ms/step - loss: 0.0686 - accuracy: 0.9882 - val_loss: 0.0671 - val_accuracy: 0.9792\n",
            "Epoch 16/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
            "Epoch 17/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0414 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
            "Epoch 18/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
            "Epoch 19/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
            "Epoch 20/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
            "Epoch 21/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
            "Epoch 22/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 23/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
            "Epoch 24/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 25/150\n",
            "169/169 [==============================] - 1s 6ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 26/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 27/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 28/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 29/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 30/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 31/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 32/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 33/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 34/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 35/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 36/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 37/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 38/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 39/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 40/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 41/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 42/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 43/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 44/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 45/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 46/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 47/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 48/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 49/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 50/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 51/150\n",
            "169/169 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 52/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 53/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 54/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 55/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 56/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 57/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 58/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 59/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 60/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 61/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 62/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 63/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 64/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 65/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 66/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 67/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 68/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 69/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 70/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 71/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 72/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 73/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 74/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 75/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 76/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 77/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 78/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 79/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 80/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 81/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 82/150\n",
            "169/169 [==============================] - 2s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 83/150\n",
            "169/169 [==============================] - 1s 7ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 84/150\n",
            "169/169 [==============================] - 1s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 85/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 86/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 87/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 9.8434e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 88/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 9.6837e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 89/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 9.5202e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 90/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 9.3673e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 91/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 9.2185e-04 - accuracy: 1.0000 - val_loss: 9.9647e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 9.0717e-04 - accuracy: 1.0000 - val_loss: 9.8257e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 8.9451e-04 - accuracy: 1.0000 - val_loss: 9.6706e-04 - val_accuracy: 1.0000\n",
            "Epoch 94/150\n",
            "169/169 [==============================] - 1s 6ms/step - loss: 8.8057e-04 - accuracy: 1.0000 - val_loss: 9.5449e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 8.6654e-04 - accuracy: 1.0000 - val_loss: 9.3981e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 8.5423e-04 - accuracy: 1.0000 - val_loss: 9.2486e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 8.4193e-04 - accuracy: 1.0000 - val_loss: 9.1303e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 8.3034e-04 - accuracy: 1.0000 - val_loss: 8.9975e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 8.1783e-04 - accuracy: 1.0000 - val_loss: 8.8598e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 8.0631e-04 - accuracy: 1.0000 - val_loss: 8.7408e-04 - val_accuracy: 1.0000\n",
            "Epoch 101/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 7.9537e-04 - accuracy: 1.0000 - val_loss: 8.6245e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 7.8438e-04 - accuracy: 1.0000 - val_loss: 8.5356e-04 - val_accuracy: 1.0000\n",
            "Epoch 103/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 7.7437e-04 - accuracy: 1.0000 - val_loss: 8.3945e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 7.6372e-04 - accuracy: 1.0000 - val_loss: 8.2942e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 7.5362e-04 - accuracy: 1.0000 - val_loss: 8.2016e-04 - val_accuracy: 1.0000\n",
            "Epoch 106/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 7.4357e-04 - accuracy: 1.0000 - val_loss: 8.0852e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 7.3477e-04 - accuracy: 1.0000 - val_loss: 7.9675e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 7.2437e-04 - accuracy: 1.0000 - val_loss: 7.8705e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 7.1528e-04 - accuracy: 1.0000 - val_loss: 7.7683e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 7.0723e-04 - accuracy: 1.0000 - val_loss: 7.6785e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 6.9799e-04 - accuracy: 1.0000 - val_loss: 7.5979e-04 - val_accuracy: 1.0000\n",
            "Epoch 112/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 6.8974e-04 - accuracy: 1.0000 - val_loss: 7.4975e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 6.8124e-04 - accuracy: 1.0000 - val_loss: 7.4363e-04 - val_accuracy: 1.0000\n",
            "Epoch 114/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 6.7358e-04 - accuracy: 1.0000 - val_loss: 7.3277e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 6.6559e-04 - accuracy: 1.0000 - val_loss: 7.2413e-04 - val_accuracy: 1.0000\n",
            "Epoch 116/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 6.5770e-04 - accuracy: 1.0000 - val_loss: 7.1624e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 6.4985e-04 - accuracy: 1.0000 - val_loss: 7.0695e-04 - val_accuracy: 1.0000\n",
            "Epoch 118/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 6.4258e-04 - accuracy: 1.0000 - val_loss: 6.9884e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 6.3552e-04 - accuracy: 1.0000 - val_loss: 6.9103e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 6.2817e-04 - accuracy: 1.0000 - val_loss: 6.8310e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 6.2143e-04 - accuracy: 1.0000 - val_loss: 6.7601e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 6.1454e-04 - accuracy: 1.0000 - val_loss: 6.6898e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 6.0756e-04 - accuracy: 1.0000 - val_loss: 6.6186e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 6.0130e-04 - accuracy: 1.0000 - val_loss: 6.5531e-04 - val_accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 5.9494e-04 - accuracy: 1.0000 - val_loss: 6.4827e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 5.8887e-04 - accuracy: 1.0000 - val_loss: 6.4177e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 5.8232e-04 - accuracy: 1.0000 - val_loss: 6.3500e-04 - val_accuracy: 1.0000\n",
            "Epoch 128/150\n",
            "169/169 [==============================] - 2s 10ms/step - loss: 5.7652e-04 - accuracy: 1.0000 - val_loss: 6.2864e-04 - val_accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "169/169 [==============================] - 1s 7ms/step - loss: 5.7006e-04 - accuracy: 1.0000 - val_loss: 6.2640e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/150\n",
            "169/169 [==============================] - 2s 11ms/step - loss: 5.6493e-04 - accuracy: 1.0000 - val_loss: 6.1577e-04 - val_accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "169/169 [==============================] - 1s 6ms/step - loss: 5.5905e-04 - accuracy: 1.0000 - val_loss: 6.1100e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 5.5356e-04 - accuracy: 1.0000 - val_loss: 6.0352e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 5.4778e-04 - accuracy: 1.0000 - val_loss: 5.9717e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 5.4263e-04 - accuracy: 1.0000 - val_loss: 5.9138e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 5.3729e-04 - accuracy: 1.0000 - val_loss: 5.8569e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 5.3213e-04 - accuracy: 1.0000 - val_loss: 5.8105e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 5.2666e-04 - accuracy: 1.0000 - val_loss: 5.7503e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 5.2185e-04 - accuracy: 1.0000 - val_loss: 5.6970e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 5.1692e-04 - accuracy: 1.0000 - val_loss: 5.6421e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 5.1183e-04 - accuracy: 1.0000 - val_loss: 5.5959e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 5.0704e-04 - accuracy: 1.0000 - val_loss: 5.5466e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 5.0237e-04 - accuracy: 1.0000 - val_loss: 5.4850e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 4.9794e-04 - accuracy: 1.0000 - val_loss: 5.4315e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 4.9310e-04 - accuracy: 1.0000 - val_loss: 5.3887e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 4.8862e-04 - accuracy: 1.0000 - val_loss: 5.3423e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 4.8435e-04 - accuracy: 1.0000 - val_loss: 5.2941e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 4.7997e-04 - accuracy: 1.0000 - val_loss: 5.2419e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/150\n",
            "169/169 [==============================] - 1s 5ms/step - loss: 4.7548e-04 - accuracy: 1.0000 - val_loss: 5.1996e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 4.7153e-04 - accuracy: 1.0000 - val_loss: 5.1673e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/150\n",
            "169/169 [==============================] - 1s 4ms/step - loss: 4.6777e-04 - accuracy: 1.0000 - val_loss: 5.1056e-04 - val_accuracy: 1.0000\n",
            "CPU times: user 2min 7s, sys: 7.49 s, total: 2min 15s\n",
            "Wall time: 2min 22s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "# fit the keras model on the dataset\n",
        "history = model_2.fit(X_2_tr, y_2_tr,validation_data=(X_test_2,y_test_2) , epochs=150, batch_size=1)\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh6uHgbrq6H6",
        "outputId": "91138e85-c05f-42fc-dbb1-d8e3b33939f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 5.1056e-04 - accuracy: 1.0000\n",
            "Accuracy: 100.00\n"
          ]
        }
      ],
      "source": [
        "...\n",
        "# evaluate the keras model\n",
        "_, accuracy = model_2.evaluate(X_test_2, y_test_2, )\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "nE4NVuX_dGpK",
        "outputId": "55e978f9-bb19-46e5-bde2-f6dc95a6b168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 1.0000 Test: 1.0000\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Evaluate model\n",
        "from matplotlib import pyplot\n",
        "_, train_mse = model_2.evaluate(X_2_tr, y_2_tr, verbose=0)\n",
        "_, test_mse = model_2.evaluate(X_test_2,y_test_2,verbose=0)\n",
        "print('Train: %.4f Test: %.4f'%(train_mse,test_mse))\n",
        "pyplot.title('Loss / Mean Squared Error')\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.ylabel('accuracy')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoIHfhy1gEVb"
      },
      "source": [
        "# **MONK 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgoejW98xCX8",
        "outputId": "3d33b77b-5ffd-449e-af5e-75c51f8437b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "...\n",
        "# define the keras model for monk 3\n",
        "model_3 = Sequential()\n",
        "model_3.add(Dense(6, input_shape=(X_test_3.shape[1],), activation='relu'))\n",
        "model_3.add(Dense(1, activation='sigmoid'))\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i-EX6EoxCX-",
        "outputId": "6df048d2-b95f-4902-8b95-6e831b35bc7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_32 (Dense)            (None, 6)                 108       \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 115\n",
            "Trainable params: 115\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "...\n",
        "# compile the keras model\n",
        "model_3.summary()\n",
        "opt = tf.keras.optimizers.SGD(learning_rate = 0.1, momentum=0.5)\n",
        "model_3.compile(loss='mean_squared_error', optimizer = opt, metrics=['accuracy'])\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZKEDwIXxCX_",
        "outputId": "6b16f17a-90de-4b64-948b-b56d53ede593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "122/122 [==============================] - 2s 7ms/step - loss: 0.1848 - accuracy: 0.7213 - val_loss: 0.0678 - val_accuracy: 0.9653\n",
            "Epoch 2/100\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 0.0694 - accuracy: 0.9262 - val_loss: 0.0393 - val_accuracy: 0.9722\n",
            "Epoch 3/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0555 - accuracy: 0.9426 - val_loss: 0.0349 - val_accuracy: 0.9722\n",
            "Epoch 4/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0568 - accuracy: 0.9262 - val_loss: 0.0312 - val_accuracy: 0.9699\n",
            "Epoch 5/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0532 - accuracy: 0.9426 - val_loss: 0.0245 - val_accuracy: 0.9722\n",
            "Epoch 6/100\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 0.0509 - accuracy: 0.9262 - val_loss: 0.0330 - val_accuracy: 0.9630\n",
            "Epoch 7/100\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 0.0491 - accuracy: 0.9426 - val_loss: 0.0218 - val_accuracy: 0.9769\n",
            "Epoch 8/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0433 - accuracy: 0.9508 - val_loss: 0.0308 - val_accuracy: 0.9653\n",
            "Epoch 9/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0448 - accuracy: 0.9508 - val_loss: 0.0238 - val_accuracy: 0.9653\n",
            "Epoch 10/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0461 - accuracy: 0.9262 - val_loss: 0.0208 - val_accuracy: 0.9769\n",
            "Epoch 11/100\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0436 - accuracy: 0.9344 - val_loss: 0.0282 - val_accuracy: 0.9722\n",
            "Epoch 12/100\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.0371 - accuracy: 0.9590 - val_loss: 0.0240 - val_accuracy: 0.9769\n",
            "Epoch 13/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0407 - accuracy: 0.9426 - val_loss: 0.0224 - val_accuracy: 0.9769\n",
            "Epoch 14/100\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 0.0400 - accuracy: 0.9426 - val_loss: 0.0264 - val_accuracy: 0.9769\n",
            "Epoch 15/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0329 - accuracy: 0.9508 - val_loss: 0.0220 - val_accuracy: 0.9769\n",
            "Epoch 16/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0343 - accuracy: 0.9508 - val_loss: 0.0256 - val_accuracy: 0.9722\n",
            "Epoch 17/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0270 - accuracy: 0.9590 - val_loss: 0.0679 - val_accuracy: 0.9028\n",
            "Epoch 18/100\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 0.0321 - accuracy: 0.9590 - val_loss: 0.0317 - val_accuracy: 0.9630\n",
            "Epoch 19/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0264 - accuracy: 0.9672 - val_loss: 0.0279 - val_accuracy: 0.9653\n",
            "Epoch 20/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0235 - accuracy: 0.9836 - val_loss: 0.0240 - val_accuracy: 0.9676\n",
            "Epoch 21/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0193 - accuracy: 0.9836 - val_loss: 0.0142 - val_accuracy: 0.9861\n",
            "Epoch 22/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0236 - accuracy: 0.9672 - val_loss: 0.0296 - val_accuracy: 0.9537\n",
            "Epoch 23/100\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 0.0203 - accuracy: 0.9836 - val_loss: 0.0207 - val_accuracy: 0.9676\n",
            "Epoch 24/100\n",
            "122/122 [==============================] - 1s 6ms/step - loss: 0.0163 - accuracy: 0.9918 - val_loss: 0.0174 - val_accuracy: 0.9792\n",
            "Epoch 25/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0155 - accuracy: 0.9836 - val_loss: 0.0177 - val_accuracy: 0.9745\n",
            "Epoch 26/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0153 - accuracy: 0.9918 - val_loss: 0.0215 - val_accuracy: 0.9722\n",
            "Epoch 27/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0154 - accuracy: 0.9836 - val_loss: 0.0313 - val_accuracy: 0.9537\n",
            "Epoch 28/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0128 - accuracy: 0.9918 - val_loss: 0.0387 - val_accuracy: 0.9375\n",
            "Epoch 29/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.9918 - val_loss: 0.0392 - val_accuracy: 0.9329\n",
            "Epoch 30/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0126 - accuracy: 0.9918 - val_loss: 0.0235 - val_accuracy: 0.9630\n",
            "Epoch 31/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0116 - accuracy: 0.9918 - val_loss: 0.0308 - val_accuracy: 0.9537\n",
            "Epoch 32/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0111 - accuracy: 0.9918 - val_loss: 0.0327 - val_accuracy: 0.9491\n",
            "Epoch 33/100\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0110 - accuracy: 0.9918 - val_loss: 0.0265 - val_accuracy: 0.9630\n",
            "Epoch 34/100\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.0105 - accuracy: 0.9918 - val_loss: 0.0303 - val_accuracy: 0.9560\n",
            "Epoch 35/100\n",
            "122/122 [==============================] - 2s 13ms/step - loss: 0.0104 - accuracy: 0.9918 - val_loss: 0.0269 - val_accuracy: 0.9583\n",
            "Epoch 36/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0101 - accuracy: 0.9918 - val_loss: 0.0277 - val_accuracy: 0.9583\n",
            "Epoch 37/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.9918 - val_loss: 0.0289 - val_accuracy: 0.9583\n",
            "Epoch 38/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9918 - val_loss: 0.0294 - val_accuracy: 0.9560\n",
            "Epoch 39/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9918 - val_loss: 0.0328 - val_accuracy: 0.9514\n",
            "Epoch 40/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0096 - accuracy: 0.9918 - val_loss: 0.0313 - val_accuracy: 0.9606\n",
            "Epoch 41/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.9918 - val_loss: 0.0297 - val_accuracy: 0.9630\n",
            "Epoch 42/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0094 - accuracy: 0.9918 - val_loss: 0.0311 - val_accuracy: 0.9606\n",
            "Epoch 43/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0094 - accuracy: 0.9918 - val_loss: 0.0286 - val_accuracy: 0.9630\n",
            "Epoch 44/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9918 - val_loss: 0.0314 - val_accuracy: 0.9606\n",
            "Epoch 45/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0092 - accuracy: 0.9918 - val_loss: 0.0288 - val_accuracy: 0.9630\n",
            "Epoch 46/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9918 - val_loss: 0.0288 - val_accuracy: 0.9606\n",
            "Epoch 47/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.9918 - val_loss: 0.0272 - val_accuracy: 0.9630\n",
            "Epoch 48/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0092 - accuracy: 0.9918 - val_loss: 0.0287 - val_accuracy: 0.9606\n",
            "Epoch 49/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9918 - val_loss: 0.0281 - val_accuracy: 0.9630\n",
            "Epoch 50/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0090 - accuracy: 0.9918 - val_loss: 0.0327 - val_accuracy: 0.9514\n",
            "Epoch 51/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9918 - val_loss: 0.0293 - val_accuracy: 0.9630\n",
            "Epoch 52/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0090 - accuracy: 0.9918 - val_loss: 0.0323 - val_accuracy: 0.9514\n",
            "Epoch 53/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0089 - accuracy: 0.9918 - val_loss: 0.0292 - val_accuracy: 0.9630\n",
            "Epoch 54/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.9918 - val_loss: 0.0308 - val_accuracy: 0.9560\n",
            "Epoch 55/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0089 - accuracy: 0.9918 - val_loss: 0.0300 - val_accuracy: 0.9606\n",
            "Epoch 56/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.9918 - val_loss: 0.0291 - val_accuracy: 0.9630\n",
            "Epoch 57/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0088 - accuracy: 0.9918 - val_loss: 0.0292 - val_accuracy: 0.9630\n",
            "Epoch 58/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0088 - accuracy: 0.9918 - val_loss: 0.0331 - val_accuracy: 0.9514\n",
            "Epoch 59/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.9918 - val_loss: 0.0304 - val_accuracy: 0.9583\n",
            "Epoch 60/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.9918 - val_loss: 0.0327 - val_accuracy: 0.9514\n",
            "Epoch 61/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0088 - accuracy: 0.9918 - val_loss: 0.0326 - val_accuracy: 0.9514\n",
            "Epoch 62/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0087 - accuracy: 0.9918 - val_loss: 0.0295 - val_accuracy: 0.9606\n",
            "Epoch 63/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0087 - accuracy: 0.9918 - val_loss: 0.0308 - val_accuracy: 0.9583\n",
            "Epoch 64/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0087 - accuracy: 0.9918 - val_loss: 0.0303 - val_accuracy: 0.9606\n",
            "Epoch 65/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0087 - accuracy: 0.9918 - val_loss: 0.0321 - val_accuracy: 0.9537\n",
            "Epoch 66/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.9918 - val_loss: 0.0303 - val_accuracy: 0.9606\n",
            "Epoch 67/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0087 - accuracy: 0.9918 - val_loss: 0.0301 - val_accuracy: 0.9606\n",
            "Epoch 68/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 0.9918 - val_loss: 0.0322 - val_accuracy: 0.9537\n",
            "Epoch 69/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 0.9918 - val_loss: 0.0307 - val_accuracy: 0.9583\n",
            "Epoch 70/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 0.9918 - val_loss: 0.0318 - val_accuracy: 0.9537\n",
            "Epoch 71/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 0.9918 - val_loss: 0.0316 - val_accuracy: 0.9583\n",
            "Epoch 72/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 0.9918 - val_loss: 0.0328 - val_accuracy: 0.9514\n",
            "Epoch 73/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 0.9918 - val_loss: 0.0308 - val_accuracy: 0.9583\n",
            "Epoch 74/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.9918 - val_loss: 0.0313 - val_accuracy: 0.9583\n",
            "Epoch 75/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.9918 - val_loss: 0.0308 - val_accuracy: 0.9583\n",
            "Epoch 76/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 0.9918 - val_loss: 0.0317 - val_accuracy: 0.9560\n",
            "Epoch 77/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.9918 - val_loss: 0.0314 - val_accuracy: 0.9583\n",
            "Epoch 78/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 0.9918 - val_loss: 0.0319 - val_accuracy: 0.9560\n",
            "Epoch 79/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0311 - val_accuracy: 0.9583\n",
            "Epoch 80/100\n",
            "122/122 [==============================] - 1s 12ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0306 - val_accuracy: 0.9583\n",
            "Epoch 81/100\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0320 - val_accuracy: 0.9560\n",
            "Epoch 82/100\n",
            "122/122 [==============================] - 1s 9ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0311 - val_accuracy: 0.9583\n",
            "Epoch 83/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0319 - val_accuracy: 0.9560\n",
            "Epoch 84/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0328 - val_accuracy: 0.9491\n",
            "Epoch 85/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0306 - val_accuracy: 0.9606\n",
            "Epoch 86/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0311 - val_accuracy: 0.9583\n",
            "Epoch 87/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0314 - val_accuracy: 0.9560\n",
            "Epoch 88/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0313 - val_accuracy: 0.9583\n",
            "Epoch 89/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0316 - val_accuracy: 0.9583\n",
            "Epoch 90/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0308 - val_accuracy: 0.9606\n",
            "Epoch 91/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0309 - val_accuracy: 0.9606\n",
            "Epoch 92/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0319 - val_accuracy: 0.9560\n",
            "Epoch 93/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0316 - val_accuracy: 0.9560\n",
            "Epoch 94/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0320 - val_accuracy: 0.9537\n",
            "Epoch 95/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0312 - val_accuracy: 0.9606\n",
            "Epoch 96/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0312 - val_accuracy: 0.9606\n",
            "Epoch 97/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0313 - val_accuracy: 0.9560\n",
            "Epoch 98/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 0.9918 - val_loss: 0.0316 - val_accuracy: 0.9560\n",
            "Epoch 99/100\n",
            "122/122 [==============================] - 1s 7ms/step - loss: 0.0084 - accuracy: 0.9918 - val_loss: 0.0317 - val_accuracy: 0.9560\n",
            "Epoch 100/100\n",
            "122/122 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.9918 - val_loss: 0.0320 - val_accuracy: 0.9560\n",
            "CPU times: user 1min 17s, sys: 4.62 s, total: 1min 22s\n",
            "Wall time: 1min 22s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "# fit the keras model on the dataset\n",
        "history = model_3.fit(X_3_tr, y_3_tr,validation_data=(X_test_3,y_test_3) ,epochs=100, batch_size=1)\n",
        "..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkzNcUDixCYA",
        "outputId": "dfa1d2c7-ec6a-49bc-e588-f72957d51822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9630\n",
            "Accuracy: 96.30\n"
          ]
        }
      ],
      "source": [
        "...\n",
        "# evaluate the keras model\n",
        "_, accuracy = model_3.evaluate(X_test_3, y_test_3, )\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "R__ZdTvFezzt",
        "outputId": "1c55d8ca-bc36-4ba2-c8b8-93f506bd0882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 0.9918 Test: 0.9560\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dXA8d/JQkJIIJAEEAKEXXABFNlcQEEF3G3rVte2Ut9XW7Vqxda91dLaWrWvdanSWjdERaWKCipqlX1V9n0Jawj7EshkzvvHcye5SSbJAJkMSc7385kPc9d57kx4zn3WK6qKMcYYU1ZcrBNgjDHm2GQBwhhjTFgWIIwxxoRlAcIYY0xYFiCMMcaEZQHCGGNMWBYgjDGliMjDIvJarNNhYs8ChDksIrJGRIbE8POXikiXMOu/FBEVkR5l1r/nrR9UY4ks+eyfisgSEdkjIltEZIKIpNV0OqqTiAwSkaCI7C3z6h/rtJnqZwHC1Boi0hGIV9VlFeyyDLjet38G0B/Iq4HklSIiA4HHgatVNQ3oBrwVg3QkROG0G1U1tcxrapjPFhGJK7PusNITpfSbCFmAMNVCRJJE5CkR2ei9nhKRJG9bpoh8KCI7RWS7iPw3lHGIyL0issG7y14qIoMr+ZgLgAmVbH8duFJE4r3lq4H3gEO+dMaJyEgRWSki+SIyVkSa+ba/LSKbRWSXiHwtIif4tv1LRJ4VkY+89E73glY4pwFTVXUugKpuV9VXVHWPd64MERkvIrtFZIaI/E5EvvG25XilnuLM0Ssh/cx731FEvvDSv01EXheRdN++a7zv9Ttgn4gkiEg/EZni/Qbz/SUqEWkvIl951zQJyKzkO66Ul87HRORbYD/QwbuWW0VkObDc2+9mEVnh/T2MF5FWvnOU29/EhgUIU11+C/QDegI9gD7A/d62u4BcIAtoAfwGUBHpCtwGnObdZZ8PrKnkM4YDH1WyfSOwCDjPW74e+HeZfX4BXAoMBFoBO4Bnfds/BjoDzYE5uKDjdxXwCNAUWAE8VkFapgPni8gjInJ6KFj6PAsUAMcBP/FekRLgD176uwFtgIfL7HM1LqCm477zj4DfA82Au4F3RSTL2/cNYDYuMPwOuOEw0hLOdcAIIA1Y6627FOgLdBeRc7z0X4G7/rXAmDLnKN7/KNNijoaq2steEb9wGfiQMOtXAsN9y+cDa7z3jwIfAJ3KHNMJ2AoMARKr+NwUIB9IqmD7l8DPgGuBN4HjgWXetlxgkPd+MTDYd9xxQCGQEOac6YACTbzlfwEv+bYPB5ZUkuZhwH+AncBe4Ekg3nsVAsf79n0c+MZ7n+N9bkLZ66vgcy4F5pb5jX7iW74XeLXMMZ/iAkFbIAA08m17A3itgs8aBAS9a/K/GvnS+WiZYxQ4x7f8MvAn33Kq933khNvfXrF7WQnCVJdWlNwt4r0PVRs8gbvbnigiq0RkJICqrgDuwN39bhWRMf6qhjIGA1NU9WAV6RgHnIMrmbwaZns74D2vqmUnLmAUAS1EJF5ERnnVT7spKc34q1w2+97vx2VuYanqx6p6Ee6u/RLgRlwQywISgPW+3deWO0EFRKSF911t8NL5GuWrhfznbgf8KHTN3nWfgQuOrYAdqrrvMNKyUVXTy7z8x68Pc4x/Xam/FVXdiwv+ras4h6lhFiBMddmIy4hC2nrrUNU9qnqXqnYALgZ+FWprUNU3VPUM71gF/ljB+YdTefsD3vn246qJ/ofwAWI9MKxM5pasqhuAa3AZ+RCgCe5OHlyVzhFT1aCqfg58AZyIazQP4KqGQtr63ocy2xTfupa+94/jvquTVLUxrtRUNo3+aZrX40oQ/mtupKqjgE1AUxFpVEFajkS4KaL960r9rXifnQFsqOIcpoZZgDBHIlFEkn2vBFy1zv0ikiUimcCDuDtbRORCEekkIgLswt2xB0Wkq4ic49XPFwAHcNUX4Qyj8vYHv98AA1V1TZhtzwOPiUg7L21ZInKJty0NOIi7m03BZcRHREQuEZGrRKSpOH1w7R7TVLUIV9J5WERSRKQ7vnp/Vc3DZZbXeqWanwD+xvA0XJXVLhFpDdxTRXJeAy4SkfO98yWL666araprgVnAIyLSQETOAC460uuO0JvATSLS0/vtHwemV/B7mRiyAGGOxARcZh56PYxrAJ0FfAd8j2vg/b23f2fgM1ymNhX4u6pOBpKAUcA2XNVNc+C+sh8mIicCe1V1XSSJU9WNqvpNBZufBsbjqrv2ANNwjaHgGrTX4jLnRd62I7UDuBnXCydUDfSEqoYavW/DVU9txrVt/LPM8TfjMv584ARgim/bI8ApuGD7ES7YVEhV1+NKRr/BlV7We+cO/f+/BvcdbAceonzDflmtpPw4iB9UcYw/PZ8BDwDv4kowHXGN/+YYI6pWkjPHNhH5NZCpqr+OdVqiRURuxDVCnxHrtBgTYoNQTG2wBtcbyBhTgyxAmGOeqo6NdRqMqY+siskYY0xY1khtjDEmrDpTxZSZmak5OTmxToYxxtQqs2fP3qaqWeG2RS1AiMho4EJgq6qeGGa74LocDseNSL1RVed4226gZB6f36vqK1V9Xk5ODrNmzaqu5BtjTL0gIhWOnI9mFdO/gKGVbB+G6x/fGTex13MA4mbWfAjXL7sP8JCINI1iOo0xxoQRtQChql/jBt5U5BLg3+pMA9JF5DjcJG+T1E2PvAOYROWBxhhjTBTEspG6NaUn5Mr11lW0vhwRGSEis0RkVl5ejT8Txhhj6rRa3YtJVV9U1d6q2jsrK2wbizHGmCMUywCxgdKzWWZ76ypab4wxpgbFMkCMB673ZrrsB+xS1U24B5mc582C2RT3dLBPY5hOY4ypl6LZzfVN3NOnMkUkF9czKRFAVZ/HzQg6HPcgmf3ATd627SLyO2Cmd6pHVbWyxm5jjDFRELUAoapXV7FdgVsr2DYaGB2NdJnI7dx/iAnfb+bK09oQH1fyPJqDgSLGzsrlh6dk07BBfPF6VeW16evI210Qi+QaU2+1bNKQa/oe7XOeyqszI6lN9fvjJ0t5c8Y6GiXFc0nPko5k/56ylscmLGbbnoPceW6X4vWfL97KA+8vAECO6hlsxpjD0bNNugUIU3PW5e/n7Vmut/FTny3ngpOOIyE+jr0HAzz31UoAXv5mNTcOyKFpowYEg8pfJi0jJyOFz341kIT4Wt1BzhhDLe/maqLn6c+XEx8n/O7SE1m9bR/j5rqOZK9MWcP2fYf40w9OZt+hAC/+dxUAnyzczOJNu7l9SGcLDsbUEfY/ub7alw95S8NuWrF1L+/NzeW6fu24tm9bTs5uwtOfLSd/70Fe+Golg49vzhWnteGik1vxr2/XsHV3AU9OWkan5qlc3CPsmEZjTC1kAaK+mvQAvHJx2E1Pf76c5MR4bhnUERHhznO7sGHnAa75x3R2FwSK2x1uH9KZg4Eirnt5Biu27uWOIZ1LNWYbY2o3a4OoR+av38mkRVsA+NniL0k/uBkKdkNy4+J9lm7ew4ffbeR/BnYkMzUJgEFdsji1XVNmr93BsBNbcmLrJgB0zErl8lOyeWd2Lse3TGP4icfV/EUZY6LGShD1yO8/WsT/TV7B21/NJv2ga1M4uG11qX3GzcklIU4YcVaH4nUiwshhx3Nck2R+5eu1BHD74M60Tm/Ib4Z3I85KD8bUKRYg6on9hwLMXbeTWwZ2ZPp1acXrVy9fWGq/KSvz6dW2KekpDUqtPy2nGVPvG0znFmml1rdplsK3I8/hrC42F5YxdY0FiHpi5podBILKgI4ZsH46Km6A26a1JQ3Vu/YXsmDjLrcPgCrkr4xFco0xxwALEPXElJXbSIwXeuc0hXXTkeze7JMU9m9ZVbzPtNX5qMKAjpluxayX4W+nwIx/xCjVxphYskbq6rR+JuxaByf+oOJ99myBBe/AaTdDgq8aZ18+TP0bHNxb+WfEJUDvn0BWl8r3K2Paynx6tkknRQKwaR70vYW9+dtpuHc9+w4GaJSUwNSV+SQnxtGjjWuEZu5r7t8J90CjTDjhssP6TGNM7WYBojpN/C1snAcdz4GGFTwl9es/wcyXYMMcuPwfEBfngsLrP4RN8yG5SeWfcWgfLBwHP50ITXMiStauA4V8v2EXt53T2X1G0SFo24/4dYvJ3ruImWu2M6hrc6auzOe0nGYkJcRD3jLYOBfOeQCWT4JxI6BhM+gw8PC+E2NMrWUBorrszYP1MwCFhe9D75vK7xM4BAvehdSWrhTRKAvOfRTGXufu6q98HY4fXvnnbF0Mo8+HVy93QaJRZpVJm7F6O0HFa3/4xK3M7kN6q/+Ssv5r3l2xjRNbN2Hplj1c0quV2/7dGJA46HUdnPZTGD0MxlwDgx9y1xafeHjfjzGm1rE2iLL25rlSwMZ57m678ED5fQ7sLF8VtHwioK4E8N1b4c+9fCIc2AEX/w36/g9Mfw5eOAtWfgEXPV11cABo3g2uGQu7N7hSx8E9VR4ydWU+SQlx9GqbDuunQ7MOkJpFQkYHUuQgi1euZNqqfAD6d8iAYBC+G+tKQmktXGnounHQqhd8fA882xcWja86rcaYWs0ChN/2VfB0D3hxoHu9cBY8c4qriw8WuaAw+Q/wZHd486rSxy6dAI1bw4BfwLqpsGNN+fN/N8aVGjqeA+c/Dif+EPIWu2qcU66PPJ1t+8GPXnFBbNrzVe4+ZeU2euc0JSk+zpVy2vR1G5q2A2Df5hV8vGAzqUkJnNS6CaybArvWw8m+a2zcCm74jwtO8Ymu1LPmm8jTbIypdSxAhKjChF+7apUfvQJXvQk/eBkaHwcf3ArPn+F69Hw1ymWsa/7rVSkBhQWuFNBlKJx8pVv33djS5z+wA5Z96oJCfIJre7jsBfj513DmXYef3q5DISUD9mysdLf8vQdZsnmP65m0YzXs2wpt+riN6S5AtCaPCd9vom/7Zm6ivfljoEEqHH9B6ZOJQJfz4Wefg8TDqq8OP93GmFrDAkTIkg9hxSQ4+z444VJX3XPSD11m+MN/ugCS0Rl++hn8dJKrSpryN3fsmv9C4X7oOhzS20K7M1wmq1py/oXvucbhHleWrItPgON6HPnDE5KbQMGuSneZtso9jK9/x4ySgBYqQaS7+ePbJ2xD1dun8AAs+gC6XQwNUsKfNCkVWp4I66cdWbqNMbWCBQhwPYM+HgnNT4A+Py+9TQROvBxunQY3fQRtTnMZZO+fwuL/uGqppRMgsRHknOGO6XElbF8JG2aXnGf+W5DZFY7rWX3pTm7s5lKqxNRV22jUIJ6TGh9wVWVJjSHreLexQQqktqBXqgsy/TtmwLJP4ODu0oEsnDZ9IXc2FAWq40qMMccgCxAAXz8Bu3Phgr+4u/pI9P25q4uf8n+w9BPodA4kJrtt3S+BhGSY/S/Yuc6Nj1g/zWW61fmotSpKELsLCvls3ir+mPERic+eCuumwcB7Ia7kMaGkt6N7ynZObdeUbi0bu6DXKAtyzqz8s9v0hcJ9sHVh5fsZY2ot6+aav9JVFfW4Btr1j/y4tJZw8hUw+5+gQehyf8m25Cauumnuq+4FgMBJV1Rr0klqDHs2h99WFGDG23/hP/p3snbscoPcBj/oejD5NW1H8/XTefe2AVBUCMs/g+4XlQ4i4YTaMdbPcNVkxpg6xwJE0xwY/mc4/sLDP7b/bd5oY6/x1m/oKOg0BPDaIZq0gfQ2R5nYMioqQaydStH4XzIkfxnLG55E1rVPQXbv8OdomgMLxrmqorVT4OAuF9yq0qQNpLVy3Wb73Fz1/munuEbxJpU8UChvqavua31K1ec7EoUFrp2p9amuV1ZIsAhWfO6+C/8IdVVY+y0kNnTH+G2c56rics4sXSrctsJ1QS47oPDQfteR4fgLSu8fDMLiD9x3npAUPt1FAVg8HvZudcsirkOE1wvNmGixABEXH35QWySad3N35gf3lh+wltYCev346NNXmeQm4dsgJtzN/j07uKvwTu76+a/guMbl9wlJbwda5KrYln4M8UnQYVDVny3iShHrple9ryq8foXL+G+oZPzEe7dA/gq4baYroVWXYBC+fxu++J3rvpvQEPrfCqffDrkzYOKDrqpM4lx340G/cZn8pAddBwRwNxBDHnHX/fkjriEfoG1/OO/37nv88g+uWlGDcOfC0sFw2t/d59/wH2h/Vsn6xePh7RtdT7bBD5ZOt6rr+fbZQ5C3pPS2lV/ANRWMtzGmmliAOFo/GF297QqHI7mJawcoKiw1sjm4ZwsfF5xM0omX0LWy4AAld6E71rjG9g6DoEGjyD6/TV9Y9D7s3lj6jrysPZvh0B5Y/RVs+g6OO7n8Prs3wcY57v3EB+AH1TRB4IGd8Opl7tzH9YDzH3OD/P77Z5dpF+53JYfLXnBTi8x8yfVACxRASiYMe8KV0r59Cp7t44JIfCIMHAmpzeHLUfDSYBd0ig65asf5b8L3Y+GMO10aVN05wXVW8AeI0Ppvn4EeV0NmZ7dcsAvGXg+rvoRmHeGKV0s6QXz9BMx4EfZti2gkfSkrJ7vR/KffXvJZwSKX5rVTYPgTpX//3Zvgk3tdN21w3Z/P+z1kdDy8z60Nvn3alWD731r1lDd+RYXuxmDJh+7mAKBRc/ddpjSr+vhD+918Z7vWuWWJd+OpOg0+7EuobhYgjlZc9bTzFxQW8fr0dVzXrx0NEiI8Z5KX+R/cw/tLD7Bw4y5Q5d79O9geTOGOIZ2rPoc3FoJln8LOtXDGHZEnOtRddv0M1zW4Ijt8DyWa8rfwmf8ybwqQbhe7zPWU66G9r6H80L7S3YZD4huUnvSwrJkvueBw6XNu4F9cnOtE0P9WmP6CCxqn/dRV7/S4CvqMcBlFWktXhRh62t6pN7j1wSL3HYVKOCdfAVP/7komoUx3+yoXCE6/w908bJwD+ctdwFn0gZcJp7gMfsUkFxiWTIAJd8N170PgIIz5sRtwOexPbnJG/9Qmva51wW3Bu66zREjo+6nohiUYhI/vhW1LYd4bcOqN7obgqz/ClgVun9TmMOThkmM+/rX72whV+63+Gsb/Em78sHxVWbj/CxWlSdX9puEkJEfeWQRc1WHQ600Xl1DSWeRw7NsGnz/qzjPzJXcDcOqN5f+2yqZ71WT47GFX8s3qBg3T3frF/3E3XTeMr/qG679/gXmvuf9PEge7Vrtpba7/wA2KjSELEMeIL5Zs5XcfLqJF4yQuPLmSu3E/7y5n7caN/GrsWhLi40iLO8hv4wJ0ateWjlmpVZ+jcWv3nyo0c2uXoZEnuuVJ7j9zVQFiuzeleNfhLlMb8hA0yS69z7JPXLC67AU3L9WEu+GWb9ykhpMerHjMRUJD6P+/LjNOLlNaKixwQaDTEOh5TeltrU+By18of76MjnDxM+XXpzZ3pY+yktJg0L2l1518JXz0K9j8nQtA899yVXcXPQVvXQvLPnYz/i4Y5zKk/re5No4Jd7vvZ9H7rmrr8n+4AFRWixOgxUmu9BEKEMEgvHGFC3RXvhY+SCyf6ILD0FGuc8as0W5K96Y5bqzP8omuV16Pa1xbzIrPXBXYOffDWfe4c8waDR/e6arsQmnbsghevdQF2FA1HLiZi/99sWunueDPJelQdaWjxRVUN6ZkuN52p97kMuiti2HSQ1571wg4/Zfue9+1ASY/5ko/oTt3xKXjnPvd39jBve6mZMYL0Lq3m/usRffyn7ngXfdbXPaiy6w/vsdNhTPkYXfTIuKC48QH3N+nX2ZXuHqM+78TuvbFH7rZBsbeAFe/WfHcZduWw5Rn3N/M5S+6dfu2ufnW3rgCbvokfHpriAWIY8TSzW5Opakr8w8jQLgMccx/F5Kc2IT//vpsMory4K8w5JSukZ0jPsH9R9qxxo3RqKyqqKyEBi5jW19FO8T2VS4Inf+Yuxud9lzpzPbQfleVcupN7s562J/cVCYvDHRtA6ktYdB9kBhm4N6mee4ObPYrMGgknPazkv+k3491I8cH/DLya6oOJ1wGn4x0gaF5d5f5dB0KXS9wAXn+Wy5AfDcGWpzoBh027+Z6vI0b4dqEzv9D+OAQ0uNKmHi/y2AyO8P8N1xpBNznnfTD8sdM+Rs0znbfUXwi9L3Ffb9dhrrAknOmq2accBdc87ar9sjoVPr7O+UGdzPx6W9dx4yCXfDa5a4K6tun3Yy/Z9zhrf+BazvJW+LGErUb4M6xcJwLDr2ug8yy09arC0wf/xqmPw/Zp7lg1CDNjUH6+k+uOqfL+W69Bt31NPE6gOzKddsXvgcn/cgFvb1boONg1970/OnQ88cuUPirf+aPcTc8Pa503/vySe7GZOz1kN3HzUe2/FP3OWffX9KhoHEr6H5p+RJPtwvhwr/Cf26Hd39WMitBQhJ0Ps91fFB1NwUJDeHc35Uc2ygTrh0HL5/nvtvBD1Xdq7BhM+g8pPJ9joAFiGPEsi0lASJiXgli/vK13DTwYjJSk2CzV1dc0XTj4aS3cwGi67DIjwlp08fddRYecH/04Wxf5UZtN+vgMs/Zr8DAX5fU86760tX5d/VKL12HuUbhlZNdg/GA2yovpve/zf1nnnC3yyDOfcTdUU/5P2h5cuk6/5qQ0sxlAt+/DTmnw/5tJdVbJ/3IZdRrp7qBlKGMIS4eLngS/jkcBtzhSkWVOelH7prnj3HVZZMehDb9IHDAZd6dzytdotowG9Z+A+c9VnI3m9nJvUJSs9y8YBPudhnT9lWuysvfuyou3o0XevFsN7g0d6Zrx7n5C/jmr65BPbmxKx3lLXalmU/ug4/uctPKBApc+o7r4SaoDJfxDfhlSQa9YJwLZGfd477X3FnuLn7uq67b+Dn3l+/NNeA2+OIxt0/b/nDVG64X3/7t8PWfXfvNns3w47fdzcS25a4a8DzvpkUEupzn5kyb9zpMftz1sDv3UTeQNtIqrFNvhH158MXvXakwpHG2S3d8ovvbH/aE69Ti17SdmyDzn8Ph/Vuq/qzWvS1A1GXLtuxBBFZt28emXQc4rkkFma2f1waRlXiQm8/0xjccOIIA0bQdrOYIA0RfCP7VVQXlnB5+n+2roWl7937AbW6q8+kvwkCv2mLpBEhqAu18x//oX67RN5IG89anuN5BH97pGpNTm7uG3W1L4fKXYtOJoMdVrtHy43vd3V2nISXrv30Kxt3s6ptP+lHJMdm94d7VkV1zWkvXfvDdWBeADux0GXegAF4a4hrPhz5esv+Uv7nv+NQbKj9v75+4EsLab10w73h2+X1a9XLtNjNfclWM173v7r4vfd5lwh96jfOX/wO6XQQIvPVjV923Z5PLnK98reK74lAG3Wmw+xvw33hk94abJrigVNH3lN7WVR9e+KQrdYZ+/5Rm7jtp3Mo9u2XJR+5Of743tX3ZUld8gvu+el7jSioVdUOuzFn3uBJLaFboHWtcwHj/Fve9tDzZfZfhtDgB7vjeBZmqHEnaIhDVACEiQ4GngXjgJVUdVWZ7O2A0kAVsB65V1VxvWxHwvbfrOlW9OJppjaWCwiLW5O/nnK7N+XzJVqauzOfyU7KrPG7JzjiOBy7skkJ6iteYdiQBotslrr6+ZZjeRVUJNVSvnRI+QKi6AJF9mltu1cuVDr583P0H6DLUVTt1Gly6njY+8fCeOSHiMsj9+fDpb9xdWuPsyttGoqnzeZCc7hqv/U8PbN7Nfc+bv4MOZ7vJIP0i7UEGrlTy3ghXpdLvf11VFbgG/unPu27WLU5wmdKiD1zPmKS0ys8ZF++mo5/8uJtxuCLn3O/aAHr/pGSAaUIDuPJVN7llh7NLqsiOv8B9H5MfdwHslOsrHpdTNi1xYW6URCL7nirap+/PXcngk5ElQbbD2RV3rT7aZ5/4q20zOrrPWjjO/W7n/b7y6qPkxuXb1mpQ1AKEiMQDzwLnArnATBEZr6qLfLv9Gfi3qr4iIucAfwCu87YdUNVqnLioZi3auJtxc3JDw+TIyUjhuv45YfddlbePoqBycc9WzF63o8IAoaq8/M1qNu0qAOD75esZC5zZ1tfT4kgCROchR148TWnm7h5Xf1VSIvDbv90NvvOP4L7sBdd4+c5NLqPZtzWywXlViYt3d62v73CNvOc/HrsHGyUkuXr3WaNdqcGvx1UuQJRdf7i6XQgfNnJzgw26r2T9kIddL5rnz3BtP8Ei13WybwRVFeC6IV8zpvJ9GjYNv09SGlzx79LrRGDYH+HZfq5accjDkaUjWuIT3c3EP72HYO1aB4MfqLnPj/NKK+HaiY4x0SxB9AFWqOoqABEZA1wC+ANEd+BX3vvJwPvUAcGgcvfb81m2ZQ/JifEcKgpyKBDkgpNb0axR+S6ZofaHbsc1pl/7DKaszEdVkTJVI5OXbuX3Hy2mYWI88XFCPIBAcsD38KIjCRBHq/1AmPGP8O0QoR5M/gCRlOoaQUef7xpaJb766k8Tk12d84J3XffRWBp4rysxlR2FfeqNEJcIJ1x+dOdv0Ah+9E/XfdZ/l5nSDK59xwWJkON6HF4HhOrWrIOr809KjWxsQLS1G+D+Pua/6SbaLDu1vQGiGyBaA+t9y7lA3zL7zAcux1VDXQakiUiGquYDySIyCwgAo1S1XPAQkRHACIC2bdtW/xUcoU8WbmbRpt08eUUPLj8lm6+W5XHD6Bks27KHfh0yyu2/dMseEuOFnIxGDOiUwScLN7N++wHaZpT02lFV/jJxGW2bpfD5XQNJjPf6nD+e5qZ8CDmww40NqKjBOBraD4Sp/+d6M3UYVHpbuAAB0CjDNcK9fJ7ryVOdAS258ZGPjq9OaS3DPwiqQSPoO6J6PqPsFC8hrU8tH5hi7Vh7nvm5j7rZA7pddHhVe/VIrGdzvRsYKCJzgYHABqDI29ZOVXsD1wBPiUi5oZuq+qKq9lbV3llZWTWW6MoUBZW/TlpGx6xGXNLTTbXQtYWr9w2VFMpavmUP7TMb0SAhzj03GvcUOL9PF25m4cbd3D64c0lwgPLzMR3Y4TLbmmyYbdffVWWEe4DQjtWAhJ83KL0t/GKOuws2pqalNnfTugx/ItYpOWZFM0BsAPyz02V764qp6kZVvVxVewG/9dbt9P7d4P27CvgS6BXFtFab/8zfyPKte7nz3C7Ex7lMujI1RdIAAB6GSURBVEXjJNKSE4rHOpS1dMseunhBpGNWKllpSUxdVdLdtSioPDlpGR2yGnFprzKT3SU3Dh8galJSmrtbXf11+W3bV7lxFhX1smiQUnXDqTHRktq8ZkvbtUw0A8RMoLOItBeRBsBVQKmhkyKSKSKhNNyH69GEiDQVkaTQPsDplG67OCYFioI89dkyjm+ZxvATS3qniAhdW6SFLUHsOxhg/fYDxaUMEaF/h5J2CIAPv9vIsi17uXNISdApVq4EsbPmAwS4sQYb55SfXXb7KmjWvubTY4w5alELEKoaAG4DPgUWA2NVdaGIPCoioS6rg4ClIrIMaAGEhtd2A2aJyHxc4/WoMr2fasQH8zaEvev/culWpq0qP6Bt3JwNrMnfz6/O7UJcmYy8S8s0lm7eU5zphyzfurd4e8iAjhnk7TnIfeO+5+HxC/nTJ0s5vmUaF5xUpkskuLEQpdogYhUgBrq+4munlF6/fVX59gdjTK0Q1XEQqjoBmFBm3YO+9+8A74Q5bgpwUjTTVpXdBYXc+dY8zj+hJc9dW9LYp6rc++53NE1pwCd3lB6hO25uLp2bp3Ju9xZlT0fXFmm8URBg656DtGhcMhJzmReAQlVMAGcf35zW6Q2Z8P0mABLi43jsshPLBR3AlSC2LS1ZPrAj/Gyp0ZZ9mhs0tfrrkgF3BbvcuAQLEMbUSjaSugIzV28nqDBtVT7BoBZnzqu37WPL7oNs2X2Q/L0H3fQWuMFuc9bt5Pp+7cp1T4WSALB0857SAWLLHpIS4mjbrKTHUovGyXw78pzIElr2udSxaIMA1720bb/SDdXbvVlcLUAYUyvFuhfTMWuKNyfSjv2FLPFVM03xzZU0bdX24vdz1u7gUCDIgE7lu7ECdGnhZlYt2w6xdMseOrdILd+2EKlQG4Sqmya6cF/JlMM1rf1ZbvK3vd7UAKEurk2tDcKY2sgCRAWmrMynY1Yj731Jl9OpK/Np0TiJ1KSEUuunrMwnPk44LSf8IKCM1CQyUxuUa9NY5uvBdESSGrvZPwv3u/YHiE0JAlw7BMASb4BW8RgICxDG1EYWIMLYvu8Qizft5tKerWmf2ai4QToYVKatyuf0Tpn0ad+sVFfUqavyOal1E9KSK57aoUuZnkw79x9iy+6DxT2YjkhoRtSCXbEZRe3XqpebGvnjkbDmG1fFlNrSBiEZU0tZgAhjupfxD+iUQb8OGUxftZ1AUZBlW/eQv+8Q/Ttk0L9DBqvy9rF5VwF7DwaYv35n8SC3inRpkcbyrXsJBl1PpmVb9havP2KhKRYKdpcEiOQYVTHFxbvnJDdtB29e7aaXtvYHY2otCxBhTFmZT0qDeE7OTmdAxwz2HAywYONupqxwgaN/xwz6e8Fg6qptzFyznUBQGdCx8ucDd22Zxv5DRWzY6ab+fW9uLg3i4zgp+zCef1vWsVSCAG8eoHFu8NuONRYgjKnFrBdTGFNWbuO0nGYkxscVz500dWU+c9btoF1GCtlNU2jVRGnSMJGpK/NpmtKABvFxnNqu8ozZ35MpqMrbs3L5cd+2ZKYexVzuSV6AOLj72AgQAOlt4Np34ZWL3FPAjDG1kgWIMrbuLmBl3j6u6O1mCclKS6JLi1S+WZHHd7m7igerxcUJ/To0Y4oXIHq2Tadhg8ofC9jZ68m0dMseJizYRHyccOvZnSo9pkr+EkRBjBup/Zp3g7uWVv2oRGPMMcuqmMoINTz7q4sGdMzk2xX57CkIFFcthdbn7jjA9xt2Vdn+ANA4OZFWTZKZuGgL78/dwPX929G8cYSPL6xIcRuEV8UkccVPmos5Cw7G1GoWIMqYsiKfxskJdG9Vksn6g0LpAFE6WESiS8s05q/fSXJiPLcMLDdB7eEr2waRnO4eSGKMMUfJcpIypq7Kp2+HjFID1/q1z0AEOjVPpXlayR1/p+apZKYmkZwYR482kTU0h7q03nR6TvEo7KOSkOwePhNqgzgWqpeMMXWCtUH4BIqCrNu+n8tPKT2ldpOURC7vlV2qVAFu5tVr+7Vl14FCkhIiq045+/jmzFiznZvPrKbePSIlo6ktQBhjqpEFCJ/CIjc+IVxm/5creoQ95o4hXQ7rM/p1yOC9/z398BNXmdB8TAd2uMdPGmNMNbAqJp/CYBCAxPgafBpbdbAShDEmCixA+AS8EkTCkU6cFyuhZ0Ic2BG7ifqMMXWOBQifwiJXgkiIr2VfS3IT2L/dlSKsBGGMqSa1LCeMrlCAaFAbA8SuXPfeAoQxpprUspwwuoqrmGpjG0TAze9kAcIYU10sQPjU6iqmEAsQxphqUstywugKdXNNrI2N1CEWIIwx1cQChE+guJtrLftarARhjImCWpYTRldhrW2DsBKEMab6WYDwCbVB1OoSRKyeJmeMqXNqWU4YXbV6oFzo33ibPcUYUz0sQPgUT7WRUMu+llAJwkoPxphqVMtywugKFPdiqmVfS6gNwqbZMMZUo1qWE0ZXyTiIWlrFZA3UxphqFNUAISJDRWSpiKwQkZFhtrcTkc9F5DsR+VJEsn3bbhCR5d7rhmimM6TWNlLHxUODNAsQxphqFbWcUETigWeBYUB34GoR6V5mtz8D/1bVk4FHgT94xzYDHgL6An2Ah0Qk6rlfcRVTbStBALTqCceFf2aFMcYciWh2eekDrFDVVQAiMga4BFjk26c78Cvv/WTgfe/9+cAkVd3uHTsJGAq8GcX0Fg+Uq3VTbQDc+GGsU2CMqWOimRO2Btb7lnO9dX7zgcu995cBaSKSEeGxiMgIEZklIrPy8vKOOsGHautUG8YYEwWxvlW+GxgoInOBgcAGoCjSg1X1RVXtraq9s7KyjjoxgdraBmGMMVEQzSqmDUAb33K2t66Yqm7EK0GISCrwA1XdKSIbgEFljv0yimkFavF038YYEwXRvFWeCXQWkfYi0gC4Chjv30FEMkUklIb7gNHe+0+B80Skqdc4fZ63LqoKa+tkfcYYEwVRywlVNQDchsvYFwNjVXWhiDwqIhd7uw0ClorIMqAF8Jh37Hbgd7ggMxN4NNRgHU2FgVo61YYxxkRBVCfuUdUJwIQy6x70vX8HeKeCY0dTUqKoEYFgEBGItwBhjDExb6Q+phQWKYlxcYhYgDDGGAsQPoGioDVQG2OMxwKET2FR0NofjDHGYwHCpzCoNKhtU30bY0yUWG7oEygKklDbpvo2xpgosdzQJ1Ck1gZhjDGeiAKEiIwTkQt8g9rqpENFQRskZ4wxnkhzw78D1wDLRWSUiHSNYppiJlCktXOqb2OMiYKIAoSqfqaqPwZOAdYAn4nIFBG5SUQSo5nAmhQIWhuEMcaERJwbetNw3wj8DJgLPI0LGJOikrIYKLQShDHGFItoqg0ReQ/oCrwKXKSqm7xNb4nIrGglrqYVFgVr58OCjDEmCiKdi+kZVZ0cboOq9q7G9MSUtUEYY0yJSG+Xu4tIemjBm4b7f6OUppgpDFovJmOMCYk0N7xZVXeGFlR1B3BzdJIUO4Eitak2jDHGE2mAiBffFKciEg80iE6SYsfaIIwxpkSkbRCf4BqkX/CWf+6tq1MKi4I0sABhjDFA5AHiXlxQ+B9veRLwUlRSFEOBoE21YYwxIREFCFUNAs95rzrLtUFYCcIYYyDycRCdgT8A3YHk0HpV7RCldMWEm4vJShDGGAORN1L/E1d6CABnA/8GXotWomIlYJP1GWNMsUhzw4aq+jkgqrpWVR8GLohesmLDpvs2xpgSkTZSH/Sm+l4uIrcBG4DU6CUrNmygnDHGlIg0N7wdSAF+CZwKXAvcEK1ExYpN1meMMSWqLEF4g+KuVNW7gb3ATVFPVQyoKkVB68VkjDEhVeaGqloEnFEDaYmpwiIFsBKEMcZ4Im2DmCsi44G3gX2hlao6LiqpioHCoiCATbVhjDGeSANEMpAPnONbp0CdCRCB4hKEBQhjjIHIR1LXyXYHv8KgK0FYFZMxxjiRjqT+J67EUIqq/qSK44biHk0aD7ykqqPKbG8LvAKke/uMVNUJIpIDLAaWertOU9VbIknrkQqVIKyR2hhjnEirmD70vU8GLgM2VnaA1/vpWeBcIBeYKSLjVXWRb7f7gbGq+pyIdAcmADnetpWq2jPC9B21kjYIK0EYYwxEXsX0rn9ZRN4EvqnisD7AClVd5R0zBrgE8AcIBRp775tQRdCJplCAsOm+jTHGOdLcsDPQvIp9WgPrfcu53jq/h4FrRSQXV3r4hW9bexGZKyJficiZ4T5AREaIyCwRmZWXl3dYF1BWIOhVMVkJwhhjgAgDhIjsEZHdoRfwH9wzIo7W1cC/VDUbGA686k3psQloq6q9gF8Bb4hI47IHq+qLqtpbVXtnZWUdVUKKq5isDcIYY4DIq5jSjuDcG4A2vuVsb53fT4Gh3mdMFZFkIFNVtwIHvfWzRWQl0AWYdQTpiIgNlDPGmNIiLUFcJiJNfMvpInJpFYfNBDqLSHsRaQBcBYwvs886YLB3zm64BvA8EcnyGrkRkQ64Kq1VkaT1SAWKQt1crQRhjDEQeRvEQ6q6K7SgqjuBhyo7QFUDwG3Ap7guq2NVdaGIPCoiF3u73QXcLCLzgTeBG1VVgbOA70RkHvAOcIuqbj+cCztcoRKEtUEYY4wTaTfXcIGkymNVdQKu8dm/7kHf+0XA6WGOexd4t+z6aAoErQRhjDF+keaGs0TkSRHp6L2eBGZHM2E1raSR2koQxhgDkQeIXwCHgLeAMUABcGu0EhULhTYXkzHGlBJpL6Z9wMgopyWmbLI+Y4wpLdJeTJNEJN233FREPo1esmpeqA3CGqmNMcaJ9HY50+u5BICq7qDqkdS1yqGA10htA+WMMQaIPEAEvZlXAfBmWy03u2ttFppqIzHBShDGGAORd3P9LfCNiHwFCHAmMCJqqYqBgE21YYwxpUTaSP2JiPTGBYW5wPvAgWgmrKbZVBvGGFNapA8M+hlwO24+pXlAP2AqpR9BWqvZM6mNMaa0SHPD24HTgLWqejbQC9hZ+SG1S3EbhJUgjDEGiDxAFKhqAYCIJKnqEqBr9JJV80IlCOvFZIwxTqSN1LneOIj3gUkisgNYG71k1bxAkRInEGdTbRhjDBB5I/Vl3tuHRWQy7vGgn0QtVTFQWBS0UdTGGOMTaQmimKp+FY2ExFphkVqAMMYYH8sRPYFg0KbZMMYYHwsQnsIitUFyxhjjYzmip7AoSAMrQRhjTDELEJ5AUdAGyRljjI/liJ7CoFobhDHG+FiA8ASKgjZIzhhjfCxH9BQWqU31bYwxPhYgPIVFQevFZIwxPpYjegJFahP1GWOMjwUITyBoJQhjjPGzHNFzqEhJTLCvwxhjQixH9LheTFbFZIwxIRYgPIEiGwdhjDF+UQ0QIjJURJaKyAoRGRlme1sRmSwic0XkOxEZ7tt2n3fcUhE5P5rpBCgM2khqY4zxO+zpviMlIvHAs8C5QC4wU0TGq+oi3273A2NV9TkR6Q5MAHK891cBJwCtgM9EpIuqFkUrvW4uJgsQxhgTEs0csQ+wQlVXqeohYAxwSZl9FGjsvW8CbPTeXwKMUdWDqroaWOGdL2oCRUqCtUEYY0yxaAaI1sB633Kut87vYeBaEcnFlR5+cRjHIiIjRGSWiMzKy8s7qsQWFqlVMRljjE+sc8SrgX+pajYwHHhVRCJOk6q+qKq9VbV3VlbWUSUkEAzaQDljjPGJWhsEsAFo41vO9tb5/RQYCqCqU0UkGciM8NhqVRiwZ1IbY4xfNHPEmUBnEWkvIg1wjc7jy+yzDhgMICLdgGQgz9vvKhFJEpH2QGdgRhTTatN9G2NMGVErQahqQERuAz4F4oHRqrpQRB4FZqnqeOAu4B8icieuwfpGVVVgoYiMBRYBAeDWaPZgApvu2xhjyopmFROqOgHX+Oxf96Dv/SLg9AqOfQx4LJrpCykKKkHFShDGGONjt8y4MRCAtUEYY4yP5YhAIKgA1ovJGGN8LEDg2h8Am+7bGGN8LEcEDoWqmGy6b2OMKWY5Im6aDcCm+zbGGB8LEJQECJtqwxhjSliOiJvqG6yR2hhj/CxAYN1cjTEmHMsR8VUxWRuEMcYUswCBlSCMMSYcyxEpGShnU20YY0wJCxC4qb7BShDGGONnOSJuqm+wXkzGGONnAQKbasMYY8KxHBH3PGqwNghjjPGzAEFJL6YG1gZhjDHFLEcEAt5IaptqwxhjSliOiK+KyQbKGWNMMQsQ+GZztRKEMcYUsxwR/0hqK0EYY0yIBQhKAoS1QRhjTAnLEbFnUhtjTDgWILCBcsYYE47liMChIitBGGNMWQmxTsCxIFAUJCFOELEAYUx9U1hYSG5uLgUFBbFOSlQlJyeTnZ1NYmJixMdYgMC1Qdg0G8bUT7m5uaSlpZGTk1NnbxJVlfz8fHJzc2nfvn3Ex1kVE64XU6K1PxhTLxUUFJCRkVFngwOAiJCRkXHYpSTLFfECRIJ9FcbUV3U5OIQcyTVGNVcUkaEislREVojIyDDb/yoi87zXMhHZ6dtW5Ns2PprpDBSpTbNhjDFlRC1AiEg88CwwDOgOXC0i3f37qOqdqtpTVXsCfwPG+TYfCG1T1YujlU5wczHZNBvGmFjYuXMnf//73w/7uOHDh7Nz586qdzwK0cwV+wArVHWVqh4CxgCXVLL/1cCbUUxPhQLBoDVSG2NioqIAEQgEKj1uwoQJpKenRytZQHR7MbUG1vuWc4G+4XYUkXZAe+AL3+pkEZkFBIBRqvp+mONGACMA2rZte8QJLSwKWgnCGMMj/1nIoo27q/Wc3Vs15qGLTqhw+8iRI1m5ciU9e/YkMTGR5ORkmjZtypIlS1i2bBmXXnop69evp6CggNtvv50RI0YAkJOTw6xZs9i7dy/Dhg3jjDPOYMqUKbRu3ZoPPviAhg0bHnXaj5Vc8SrgHVUt8q1rp6q9gWuAp0SkY9mDVPVFVe2tqr2zsrKO+MMLrQ3CGBMjo0aNomPHjsybN48nnniCOXPm8PTTT7Ns2TIARo8ezezZs5k1axbPPPMM+fn55c6xfPlybr31VhYuXEh6ejrvvvtutaQtmiWIDUAb33K2ty6cq4Bb/StUdYP37yoR+RLoBays/mS6gXJWgjDGVHanX1P69OlTaqzCM888w3vvvQfA+vXrWb58ORkZGaWOad++PT179gTg1FNPZc2aNdWSlmjmijOBziLSXkQa4IJAud5IInI80BSY6lvXVESSvPeZwOnAomglNBBUm2bDGHNMaNSoUfH7L7/8ks8++4ypU6cyf/58evXqFXYsQ1JSUvH7+Pj4KtsvIhW1EoSqBkTkNuBTIB4YraoLReRRYJaqhoLFVcAYVVXf4d2AF0QkiAtio1Q1agHiUCBoU30bY2IiLS2NPXv2hN22a9cumjZtSkpKCkuWLGHatGk1mraoTrWhqhOACWXWPVhm+eEwx00BTopm2vwCQSU50QKEMabmZWRkcPrpp3PiiSfSsGFDWrRoUbxt6NChPP/883Tr1o2uXbvSr1+/Gk2bzcWEN1lfkn0VxpjYeOONN8KuT0pK4uOPPw67LdTOkJmZyYIFC4rX33333dWWLrttxgbKGWNMOJYrEhoHYY3UxhjjZwGC0HTf9lUYY4yf5YqEpvu2EoQxxvhZgMCm2jDGmHAsV8Sb7tvaIIwxphQLEFgJwhgTO0c63TfAU089xf79+6s5RSUsV8RrpLY2CGNMDBzLAcJGh2GPHDXGeD4eCZu/r95ztjwJho2qcLN/uu9zzz2X5s2bM3bsWA4ePMhll13GI488wr59+7jiiivIzc2lqKiIBx54gC1btrBx40bOPvtsMjMzmTx5cvWmGwsQqKobKGclCGNMDIwaNYoFCxYwb948Jk6cyDvvvMOMGTNQVS6++GK+/vpr8vLyaNWqFR999BHg5mhq0qQJTz75JJMnTyYzMzMqaav3AaIo6OYItHEQxpjK7vRrwsSJE5k4cSK9evUCYO/evSxfvpwzzzyTu+66i3vvvZcLL7yQM888s0bSU+8DRKA4QFgJwhgTW6rKfffdx89//vNy2+bMmcOECRO4//77GTx4MA8++GCYM1Sven/bfKgoCEADK0EYY2LAP933+eefz+jRo9m7dy8AGzZsYOvWrWzcuJGUlBSuvfZa7rnnHubMmVPu2GiwEkSRV4KwNghjTAz4p/seNmwY11xzDf379wcgNTWV1157jRUrVnDPPfcQFxdHYmIizz33HAAjRoxg6NChtGrVKiqN1FL6OT21V+/evXXWrFmHfdyuA4X8Ztz3XHFaGwZ2OfLnWhtjaqfFixfTrVu3WCejRoS7VhGZraq9w+1f70sQTRom8uyPT4l1Mowx5phjFe/GGGPCsgBhjKn36kpVe2WO5BotQBhj6rXk5GTy8/PrdJBQVfLz80lOTj6s4+p9G4Qxpn7Lzs4mNzeXvLy8WCclqpKTk8nOzj6sYyxAGGPqtcTERNq3bx/rZByTrIrJGGNMWBYgjDHGhGUBwhhjTFh1ZiS1iOQBa4/iFJnAtmpKTm1RH68Z6ud118drhvp53Yd7ze1UNew0EnUmQBwtEZlV0XDzuqo+XjPUz+uuj9cM9fO6q/OarYrJGGNMWBYgjDHGhGUBosSLsU5ADNTHa4b6ed318Zqhfl53tV2ztUEYY4wJy0oQxhhjwrIAYYwxJqx6HyBEZKiILBWRFSIyMtbpiRYRaSMik0VkkYgsFJHbvfXNRGSSiCz3/m0a67RWNxGJF5G5IvKht9xeRKZ7v/lbItIg1mmsbiKSLiLviMgSEVksIv3r+m8tInd6f9sLRORNEUmui7+1iIwWka0issC3LuxvK84z3vV/JyKH9XS0eh0gRCQeeBYYBnQHrhaR7rFNVdQEgLtUtTvQD7jVu9aRwOeq2hn43Fuua24HFvuW/wj8VVU7ATuAn8YkVdH1NPCJqh4P9MBdf539rUWkNfBLoLeqngjEA1dRN3/rfwFDy6yr6LcdBnT2XiOA5w7ng+p1gAD6ACtUdZWqHgLGAJfEOE1RoaqbVHWO934PLsNojbveV7zdXgEujU0Ko0NEsoELgJe8ZQHOAd7xdqmL19wEOAt4GUBVD6nqTur4b42bnbqhiCQAKcAm6uBvrapfA9vLrK7ot70E+Lc604B0ETku0s+q7wGiNbDet5zrravTRCQH6AVMB1qo6iZv02agRYySFS1PAb8Ggt5yBrBTVQPecl38zdsDecA/vaq1l0SkEXX4t1bVDcCfgXW4wLALmE3d/61DKvptjyqPq+8Bot4RkVTgXeAOVd3t36auz3Od6fcsIhcCW1V1dqzTUsMSgFOA51S1F7CPMtVJdfC3boq7W24PtAIaUb4apl6ozt+2vgeIDUAb33K2t65OEpFEXHB4XVXHeau3hIqc3r9bY5W+KDgduFhE1uCqD8/B1c2ne9UQUDd/81wgV1Wne8vv4AJGXf6thwCrVTVPVQuBcbjfv67/1iEV/bZHlcfV9wAxE+js9XRogGvUGh/jNEWFV/f+MrBYVZ/0bRoP3OC9vwH4oKbTFi2qep+qZqtqDu63/UJVfwxMBn7o7VanrhlAVTcD60Wkq7dqMLCIOvxb46qW+olIive3HrrmOv1b+1T0244Hrvd6M/UDdvmqoqpU70dSi8hwXD11PDBaVR+LcZKiQkTOAP4LfE9JffxvcO0QY4G2uOnSr1DVsg1gtZ6IDALuVtULRaQDrkTRDJgLXKuqB2OZvuomIj1xDfMNgFXATbgbwjr7W4vII8CVuB57c4Gf4erb69RvLSJvAoNw03pvAR4C3ifMb+sFy//DVbftB25S1VkRf1Z9DxDGGGPCq+9VTMYYYypgAcIYY0xYFiCMMcaEZQHCGGNMWBYgjDHGhGUBwphjgIgMCs02a8yxwgKEMcaYsCxAGHMYRORaEZkhIvNE5AXvWRN7ReSv3rMIPheRLG/fniIyzZuH/z3fHP2dROQzEZkvInNEpKN3+lTfMxxe9wY5GRMzFiCMiZCIdMON1D1dVXsCRcCPcRPDzVLVE4CvcCNbAf4N3KuqJ+NGsIfWvw48q6o9gAG42UfBzbB7B+7ZJB1wcwkZEzMJVe9ijPEMBk4FZno39w1xk6IFgbe8fV4DxnnPZEhX1a+89a8Ab4tIGtBaVd8DUNUCAO98M1Q111ueB+QA30T/sowJzwKEMZET4BVVva/USpEHyux3pPPX+OcIKsL+f5oYsyomYyL3OfBDEWkOxc8Bbof7fxSaMfQa4BtV3QXsEJEzvfXXAV95T/PLFZFLvXMkiUhKjV6FMRGyOxRjIqSqi0TkfmCiiMQBhcCtuAfy9PG2bcW1U4Cbdvl5LwCEZlQFFyxeEJFHvXP8qAYvw5iI2WyuxhwlEdmrqqmxTocx1c2qmIwxxoRlJQhjjDFhWQnCGGNMWBYgjDHGhGUBwhhjTFgWIIwxxoRlAcIYY0xY/w/KsE58KEfrPAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Evaluate model\n",
        "from matplotlib import pyplot\n",
        "_, train_mse = model_3.evaluate(X_3_tr, y_3_tr, verbose=0)\n",
        "_, test_mse = model_3.evaluate(X_test_3,y_test_3,verbose=0)\n",
        "print('Train: %.4f Test: %.4f'%(train_mse,test_mse))\n",
        "pyplot.title('Loss / Mean Squared Error')\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.xlabel('epoch')\n",
        "pyplot.ylabel('accuracy')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
